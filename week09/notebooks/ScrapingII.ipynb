{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS600 - Social Media Data Mining \n",
    "###  \n",
    "<img src=\"https://www.syracuse.edu/wp-content/themes/g6-carbon/img/syracuse-university-seal.svg?ver=6.3.9\" style=\"width: 200px;\"/>\n",
    "\n",
    "# Web Scraping Tools\n",
    "\n",
    "###  October 9, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter, cont'd**\n",
    "Let's complete our look at the Twitter API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "from twitter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('auth_dict','r') as f:\n",
    "    twtr_auth = json.load(f) # loading from my personal file\n",
    "    \n",
    "# To make it more readable, lets store\n",
    "# the OAuth credentials in strings first.\n",
    "CONSUMER_KEY = twtr_auth['consumer_key']\n",
    "CONSUMER_SECRET = twtr_auth['consumer_secret']\n",
    "OAUTH_TOKEN = twtr_auth['token']\n",
    "OAUTH_TOKEN_SECRET = twtr_auth['token_secret']\n",
    "    \n",
    "# Then, we store the OAuth object in \"auth\"\n",
    "auth = OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "                           CONSUMER_KEY, CONSUMER_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can automate the API login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oauth_login():\n",
    "    CONSUMER_KEY = twtr_auth['consumer_key']\n",
    "    CONSUMER_SECRET = twtr_auth['consumer_secret']\n",
    "    OAUTH_TOKEN = twtr_auth['token']\n",
    "    OAUTH_TOKEN_SECRET = twtr_auth['token_secret']\n",
    "    auth = OAuth(OAUTH_TOKEN, OAUTH_TOKEN_SECRET,\n",
    "    CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    twitter_api = Twitter(auth=auth)\n",
    "    return twitter_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can wrap the lines that give us trends in a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_trends(twitter_api, woe_id):\n",
    "    # Prefix ID with the underscore for query string parameterization.\n",
    "    # Without the underscore, the twitter package appends the ID value\n",
    "    # to the URL itself as a special-case keyword argument.\n",
    "    return twitter_api.trends.place(_id=woe_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we define a function for the looped twitter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_search(twitter_api, q, max_results=200, **kw):\n",
    "    search_results = twitter_api.search.tweets(q=q, count=100, **kw)\n",
    "    statuses = search_results['statuses']\n",
    "    # Enforce a reasonable limit\n",
    "    max_results = min(1000, max_results)\n",
    "    for _ in range(10): # 10*100 = 1000\n",
    "        try:\n",
    "            next_results = search_results['search_metadata']['next_results']\n",
    "        except KeyError as e: # No more results when next_results doesn't exist\n",
    "            break\n",
    "        # Create a dictionary from next_results, which has the following form:\n",
    "        # ?max_id=313519052523986943&q=NCAA&include_entities=1\n",
    "        kwargs = dict([ kv.split('=') \n",
    "                       for kv in next_results[1:].split(\"&\") ])\n",
    "        search_results = twitter_api.search.tweets(**kwargs)\n",
    "        statuses += search_results['statuses']\n",
    "        if len(statuses) > max_results:\n",
    "            break\n",
    "    \n",
    "    return statuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely encounter errors in mining Twitter data. Here is a function to automate the handling of certain errors. See *Mining the Social Web* for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from twitter.api import TwitterHTTPError\n",
    "from urllib.error import URLError\n",
    "from http.client import BadStatusLine\n",
    "\n",
    "def make_twitter_request(twitter_api_func, max_errors=10, *args, **kw):\n",
    "    # A nested helper function that handles common HTTPErrors. Return an updated\n",
    "    # value for wait_period if the problem is a 500 level error. Block until the\n",
    "    # rate limit is reset if it's a rate limiting issue (429 error). Returns None\n",
    "    # for 401 and 404 errors, which requires special handling by the caller.\n",
    "    def handle_twitter_http_error(e, wait_period=2, sleep_when_rate_limited=True):\n",
    "        if wait_period > 3600: # Seconds\n",
    "            print('Too many retries. Quitting.', file=sys.stderr)\n",
    "            raise e\n",
    "        if e.e.code == 401:\n",
    "            return None\n",
    "        elif e.e.code == 404:\n",
    "            print('Encountered 404 Error (Not Found)', file=sys.stderr)\n",
    "            return None\n",
    "        elif e.e.code == 429:\n",
    "            print('Encountered 429 Error (Rate Limit Exceeded)', file=sys.stderr)\n",
    "            if sleep_when_rate_limited:\n",
    "                print(\"Retrying in 15 minutes...ZzZ...\", file=sys.stderr)\n",
    "                sys.stderr.flush()\n",
    "                time.sleep(60*15 + 5) #Handling API rate limit issues.\n",
    "                print('...ZzZ...Awake now and trying again.', file=sys.stderr)\n",
    "                return 2\n",
    "            else:\n",
    "                raise e # Caller must handle the rate limiting issue\n",
    "        elif e.e.code in (500, 502, 503, 504):\n",
    "            print('Encountered %i Error. Retrying in %i seconds' % (e.e.code, wait_period), file=sys.stderr)\n",
    "            time.sleep(wait_period)\n",
    "            wait_period *= 1.5\n",
    "            return wait_period\n",
    "        else:\n",
    "            raise e\n",
    "\n",
    "    # End of nested helper function\n",
    "\n",
    "    wait_period = 2\n",
    "    error_count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return twitter_api_func(*args, **kw)\n",
    "        except TwitterHTTPError as e:\n",
    "            error_count = 0\n",
    "            wait_period = handle_twitter_http_error(e, wait_period)\n",
    "            if wait_period is None:\n",
    "                return\n",
    "        except URLError as e:\n",
    "            error_count += 1\n",
    "            print(\"URLError encountered. Continuing.\", file=sys.stderr)\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise\n",
    "        except BadStatusLine as e:\n",
    "            error_count += 1\n",
    "            print >> sys.stderr, \"BadStatusLine encountered. Continuing.\"\n",
    "            if error_count > max_errors:\n",
    "                print(\"Too many consecutive errors...bailing out.\", file=sys.stderr)\n",
    "                raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = oauth_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = make_twitter_request(t.users.lookup, screen_name=\"SocialWebMining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 132373965,\n",
       "  'id_str': '132373965',\n",
       "  'name': 'MiningTheSocialWeb',\n",
       "  'screen_name': 'SocialWebMining',\n",
       "  'location': '',\n",
       "  'description': 'Get the source code at GitHub: http://t.co/U0VmWrXpB9',\n",
       "  'url': 'http://t.co/CJfJDyM6ki',\n",
       "  'entities': {'url': {'urls': [{'url': 'http://t.co/CJfJDyM6ki',\n",
       "      'expanded_url': 'http://miningthesocialweb.com',\n",
       "      'display_url': 'miningthesocialweb.com',\n",
       "      'indices': [0, 22]}]},\n",
       "   'description': {'urls': [{'url': 'http://t.co/U0VmWrXpB9',\n",
       "      'expanded_url': 'http://bit.ly/MiningTheSocialWeb2E',\n",
       "      'display_url': 'bit.ly/MiningTheSocia…',\n",
       "      'indices': [31, 53]}]}},\n",
       "  'protected': False,\n",
       "  'followers_count': 4339,\n",
       "  'friends_count': 0,\n",
       "  'listed_count': 219,\n",
       "  'created_at': 'Tue Apr 13 02:10:40 +0000 2010',\n",
       "  'favourites_count': 35,\n",
       "  'utc_offset': None,\n",
       "  'time_zone': None,\n",
       "  'geo_enabled': False,\n",
       "  'verified': False,\n",
       "  'statuses_count': 770,\n",
       "  'lang': 'en',\n",
       "  'status': {'created_at': 'Mon Aug 17 14:39:50 +0000 2015',\n",
       "   'id': 633287122284228612,\n",
       "   'id_str': '633287122284228612',\n",
       "   'text': 'Would you like to see a revised/expanded 3rd Ed. of Mining the Social Web? https://t.co/Bpd5UHMFw6 (If so, please RT, fav, or comment!)',\n",
       "   'truncated': False,\n",
       "   'entities': {'hashtags': [],\n",
       "    'symbols': [],\n",
       "    'user_mentions': [],\n",
       "    'urls': [{'url': 'https://t.co/Bpd5UHMFw6',\n",
       "      'expanded_url': 'https://www.facebook.com/MiningTheSocialWeb/posts/874302272625003',\n",
       "      'display_url': 'facebook.com/MiningTheSocia…',\n",
       "      'indices': [75, 98]}]},\n",
       "   'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
       "   'in_reply_to_status_id': None,\n",
       "   'in_reply_to_status_id_str': None,\n",
       "   'in_reply_to_user_id': None,\n",
       "   'in_reply_to_user_id_str': None,\n",
       "   'in_reply_to_screen_name': None,\n",
       "   'geo': None,\n",
       "   'coordinates': None,\n",
       "   'place': None,\n",
       "   'contributors': None,\n",
       "   'is_quote_status': False,\n",
       "   'retweet_count': 42,\n",
       "   'favorite_count': 134,\n",
       "   'favorited': False,\n",
       "   'retweeted': False,\n",
       "   'possibly_sensitive': False,\n",
       "   'lang': 'en'},\n",
       "  'contributors_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'is_translation_enabled': False,\n",
       "  'profile_background_color': '352726',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme5/bg.gif',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme5/bg.gif',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1154493071/Picture_7_normal.png',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1154493071/Picture_7_normal.png',\n",
       "  'profile_link_color': 'D02B55',\n",
       "  'profile_sidebar_border_color': '829D5E',\n",
       "  'profile_sidebar_fill_color': '99CC33',\n",
       "  'profile_text_color': '3E4415',\n",
       "  'profile_use_background_image': True,\n",
       "  'has_extended_profile': False,\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'following': False,\n",
       "  'follow_request_sent': False,\n",
       "  'notifications': False,\n",
       "  'translator_type': 'none'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to write responses to disk, on the fly, so that we can collect many observations for later analysis. In *Mining the Social Web*, the Mongo DB database program is recommended. Here is another way (that also can be adapted so that it writes to a database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's wrap the extraction of tweet \"[entities](https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/entities-object)\" in a function which takes a list of statuses as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweet_entities(statuses):\n",
    "    if len(statuses) == 0:\n",
    "        return [], [], [], [], []\n",
    "    screen_names = [ user_mention['screen_name'] \n",
    "                    for status in statuses\n",
    "                        for user_mention in status['entities']['user_mentions'] ]\n",
    "    hashtags = [ hashtag['text']\n",
    "                    for status in statuses\n",
    "                        for hashtag in status['entities']['hashtags'] ]\n",
    "    urls = [ url['expanded_url']\n",
    "                    for status in statuses\n",
    "                        for url in status['entities']['urls'] ]\n",
    "    symbols = [ symbol['text']\n",
    "                    for status in statuses\n",
    "                        for symbol in status['entities']['symbols'] ]\n",
    "    if status['entities'].has_key('media'):\n",
    "        media = [ media['url']\n",
    "                for status in statuses\n",
    "                    for media in status['entities']['media'] ]\n",
    "    else:\n",
    "        media = []\n",
    "    return screen_names, hashtags, urls, media, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tweet_basics(status):\n",
    "    screen_name = None\n",
    "    tweet_ID = None\n",
    "    text = None\n",
    "    if 'user' in status:\n",
    "        screen_name = status['user']['screen_name'] \n",
    "        tweet_ID = str(status['id'])\n",
    "        text = status['text']\n",
    "    return screen_name, tweet_ID, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we stick this in the streaming loop from last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_csv(file, status):\n",
    "    screen_name, tweet_ID, text = extract_tweet_basics(status)\n",
    "    df = pd.DataFrame([[screen_name,tweet_ID,text]], columns=['screen_name','tweet_ID','text'])\n",
    "    with open(file, 'a') as f:\n",
    "        df.to_csv(f,header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a *streaming* connection (not RESTful, different from Search).\n",
    "t_stream = TwitterStream(auth=auth)\n",
    "\n",
    "\n",
    "# Get an *iterator* object from the twitter wrapper\n",
    "\n",
    "tweeterator = t_stream.statuses.sample()\n",
    "\n",
    "# Create a CSV file with column names\n",
    "# but no data (yet).\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=['screen_name','tweet_ID','text'])\n",
    "df.to_csv('my_csv.csv', index=False)\n",
    "\n",
    "\n",
    "# The loop below will grab a new tweet,\n",
    "# extract some basic info, put that info\n",
    "# in a dataframe object, then use that\n",
    "# dataframe object to append one row to\n",
    "# the existing CSV file, 'my_csv.csv'.\n",
    "\n",
    "tweet_count = 100\n",
    "for tweet in tweeterator:\n",
    "    tweet_count -= 1\n",
    "    tweet_to_csv('my_csv.csv', tweet)  \n",
    "    if tweet_count <= 0:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>tweet_ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rochista9</td>\n",
       "      <td>1.049662e+18</td>\n",
       "      <td>@Pablidzic Pues yo la gente de izquierda que c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fenrirdenpadata</td>\n",
       "      <td>1.049662e+18</td>\n",
       "      <td>RT @phenixsaber: 通常人が想定するエロ(敢えて、エロ画像を張る)、自称フェミ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sanjiro_ni</td>\n",
       "      <td>1.049662e+18</td>\n",
       "      <td>うわ…潮江先輩の声が聞こえる…うるさいなあ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>taka0109da</td>\n",
       "      <td>1.049662e+18</td>\n",
       "      <td>RT @inoueyusuke: 品川駅の改札の外で、サラリーマンの彼氏の帰りを待つ彼女。\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UltraDz1</td>\n",
       "      <td>1.049662e+18</td>\n",
       "      <td>RT @DemahomTube: @charlieINTEL Black Ops 4 des...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       screen_name      tweet_ID  \\\n",
       "0        Rochista9  1.049662e+18   \n",
       "1  fenrirdenpadata  1.049662e+18   \n",
       "2       Sanjiro_ni  1.049662e+18   \n",
       "3       taka0109da  1.049662e+18   \n",
       "4         UltraDz1  1.049662e+18   \n",
       "\n",
       "                                                text  \n",
       "0  @Pablidzic Pues yo la gente de izquierda que c...  \n",
       "1  RT @phenixsaber: 通常人が想定するエロ(敢えて、エロ画像を張る)、自称フェミ...  \n",
       "2                              うわ…潮江先輩の声が聞こえる…うるさいなあ  \n",
       "3  RT @inoueyusuke: 品川駅の改札の外で、サラリーマンの彼氏の帰りを待つ彼女。\\...  \n",
       "4  RT @DemahomTube: @charlieINTEL Black Ops 4 des...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('my_csv.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Network Structure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll develop some tools for crawling the friendship graph of some Twitter followers. This exercise is taken directly from *Mining the Social Web*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will let us create new partial\n",
    "# functions with arguments set to \n",
    "# certain values.\n",
    "from functools import partial\n",
    "\n",
    "# This was maxint.\n",
    "# There is no longer a maxint (in Python 3)\n",
    "from sys import maxsize\n",
    "\n",
    "\n",
    "def get_friends_followers_ids(twitter_api, screen_name=None, user_id=None,\n",
    "                                friends_limit=maxsize, followers_limit=maxsize):\n",
    "    # Must have either screen_name or user_id (logical xor)\n",
    "    assert (screen_name != None) != (user_id != None), \\\n",
    "    \"Must have screen_name or user_id, but not both\"\n",
    "    \n",
    "    # You can also do this with a function closure.\n",
    "    get_friends_ids = partial(make_twitter_request, twitter_api.friends.ids,\n",
    "                                count=5000)\n",
    "    get_followers_ids = partial(make_twitter_request, twitter_api.followers.ids,\n",
    "                                count=5000)\n",
    "    friends_ids, followers_ids = [], []\n",
    "    for twitter_api_func, limit, ids, label in [\n",
    "            [get_friends_ids, friends_limit, friends_ids, \"friends\"],\n",
    "            [get_followers_ids, followers_limit, followers_ids, \"followers\"]\n",
    "            ]:\n",
    "        #LOOK HERE! This little line is important.\n",
    "        if limit == 0: continue\n",
    "        cursor = -1\n",
    "        while cursor != 0:\n",
    "            # Use make_twitter_request via the partially bound callable...\n",
    "            if screen_name:\n",
    "                response = twitter_api_func(screen_name=screen_name, cursor=cursor)\n",
    "            else: # user_id\n",
    "                response = twitter_api_func(user_id=user_id, cursor=cursor)\n",
    "            if response is not None:\n",
    "                ids += response['ids']\n",
    "                cursor = response['next_cursor']\n",
    "            print('Fetched {0} total {1} ids for {2}'.format(len(ids),\n",
    "                    label, (user_id or screen_name), file=sys.stderr))\n",
    "            if len(ids) >= limit or response is None:\n",
    "                break\n",
    "    # Do something useful with the IDs, like store them to disk...\n",
    "    return friends_ids[:friends_limit], followers_ids[:followers_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 957 total friends ids for ZedShaw\n",
      "Fetched 5000 total followers ids for ZedShaw\n",
      "[193322834, 56582285, 190364901, 52551600, 61391304, 259379883, 9038902, 768486347300626432, 22455722, 402502573]\n",
      "[3773329635, 41868331, 82216927, 2987896214, 906191357311541248, 417898030, 47502725, 1000090889350516736, 1840251, 596716120]\n"
     ]
    }
   ],
   "source": [
    "friends_ids, followers_ids = get_friends_followers_ids(t,\n",
    "                                screen_name=\"ZedShaw\",\n",
    "                                friends_limit=10,\n",
    "                                followers_limit=10)\n",
    "print(friends_ids)\n",
    "\n",
    "print(followers_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mostly empty data frame,\n",
    "# and write it to a CSV file.\n",
    "df = pd.DataFrame(columns=['ID','followers'])\n",
    "df.to_csv('followers.csv', index=False)\n",
    "\n",
    "# Our function\n",
    "def save_followers(fid, followers):\n",
    "    df = pd.DataFrame([[fid, followers]], columns=['ID','followers'])\n",
    "    with open('followers.csv', 'a') as f:\n",
    "        df.to_csv(f,header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's implement a (somewhat limited) BFS of the followers graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_followers(twitter_api, screen_name, limit=1000000, depth=2):\n",
    "    \n",
    "    # Resolve the ID for screen_name and start working with IDs for consistency\n",
    "    seed_id = str(twitter_api.users.show(screen_name=screen_name)['id'])\n",
    "    _, next_queue = get_friends_followers_ids(twitter_api, user_id=seed_id,\n",
    "                        friends_limit=0, followers_limit=limit)\n",
    "    \n",
    "    # Store a seed_id => _follower_ids mapping in MongoDB\n",
    "    save_followers(seed_id, ','.join([str(x) for x in next_queue]))\n",
    "    \n",
    "    d = 1\n",
    "    # Note that in the example in the next cell,\n",
    "    # we never enter this loop.\n",
    "    while d < depth:\n",
    "        d += 1\n",
    "        # Reset the next_queue so that we can\n",
    "        # start building up the next level\n",
    "        # of followers-of-followers\n",
    "        (queue, next_queue) = (next_queue, [])\n",
    "        # Loop through the current\n",
    "        # level of followers\n",
    "        for fid in queue:\n",
    "            _, follower_ids = get_friends_followers_ids(twitter_api, user_id=fid,\n",
    "                                friends_limit=0, followers_limit=limit)\n",
    "            # Store an ID with a string recording\n",
    "            # IDs of followers of the user with ID \"fid\"\n",
    "            save_followers(str(fid), ','.join([str(x) for x in follower_ids]))\n",
    "            # Extending the list\n",
    "            next_queue += follower_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 5000 total followers ids for 15029296\n",
      "Fetched 10000 total followers ids for 15029296\n",
      "Fetched 15000 total followers ids for 15029296\n",
      "Fetched 17384 total followers ids for 15029296\n",
      "Fetched 5000 total followers ids for 3773329635\n",
      "Fetched 10000 total followers ids for 3773329635\n",
      "Fetched 15000 total followers ids for 3773329635\n",
      "Fetched 20000 total followers ids for 3773329635\n",
      "Fetched 25000 total followers ids for 3773329635\n",
      "Fetched 30000 total followers ids for 3773329635\n",
      "Fetched 35000 total followers ids for 3773329635\n",
      "Fetched 40000 total followers ids for 3773329635\n",
      "Fetched 45000 total followers ids for 3773329635\n",
      "Fetched 50000 total followers ids for 3773329635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encountered 429 Error (Rate Limit Exceeded)\n",
      "Retrying in 15 minutes...ZzZ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/twitter/api.py\u001b[0m in \u001b[0;36m_handle_response\u001b[0;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content-Type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'image/jpeg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image/png'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTwitterHTTPError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b3041384e796>\u001b[0m in \u001b[0;36mmake_twitter_request\u001b[0;34m(twitter_api_func, max_errors, *args, **kw)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtwitter_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/twitter/api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muriBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/twitter/api.py\u001b[0m in \u001b[0;36m_handle_response\u001b[0;34m(self, req, uri, arg_data, _timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTwitterHTTPError\u001b[0m: Twitter sent status 429 for URL: 1.1/followers/ids.json using parameters: (count=5000&cursor=1587781745262341848&oauth_consumer_key=UA7nwNJXLMdH4LuQpn9SRLL5i&oauth_nonce=7630984819887009655&oauth_signature_method=HMAC-SHA1&oauth_timestamp=1539094948&oauth_token=935604097453056000-hcDlFBs3UI4JEOwfZLUSIB3CzZIiMOL&oauth_version=1.0&user_id=3773329635&oauth_signature=2TlqiRAs8I%2BidOuKCAEDrGJFPjk%3D)\ndetails: b'{\"errors\":[{\"message\":\"Rate limit exceeded\",\"code\":88}]}'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6d682559368f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcrawl_followers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ZedShaw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-d7d948b6a979>\u001b[0m in \u001b[0;36mcrawl_followers\u001b[0;34m(twitter_api, screen_name, limit, depth)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             _, follower_ids = get_friends_followers_ids(twitter_api, user_id=fid,\n\u001b[0;32m---> 24\u001b[0;31m                                 friends_limit=0, followers_limit=limit)\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Store an ID with a string recording\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# IDs of followers of the user with ID \"fid\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-8d55f7f0e64a>\u001b[0m in \u001b[0;36mget_friends_followers_ids\u001b[0;34m(twitter_api, screen_name, user_id, friends_limit, followers_limit)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# user_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mids\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b3041384e796>\u001b[0m in \u001b[0;36mmake_twitter_request\u001b[0;34m(twitter_api_func, max_errors, *args, **kw)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTwitterHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0merror_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mwait_period\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle_twitter_http_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_period\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwait_period\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b3041384e796>\u001b[0m in \u001b[0;36mhandle_twitter_http_error\u001b[0;34m(e, wait_period, sleep_when_rate_limited)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retrying in 15 minutes...ZzZ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m15\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Handling API rate limit issues.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...ZzZ...Awake now and trying again.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crawl_followers(t,'ZedShaw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about all of this in more detail in *Mining the Social Web*. Take care to translate from Python 2 into Python 3 if you are using Python 3 (as I have here). See if you can find the bug in the Python 2 code for `crawl_followers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dF = pd.read_csv('followers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15029296</td>\n",
       "      <td>3773329635,41868331,82216927,2987896214,906191...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                          followers\n",
       "0  15029296  3773329635,41868331,82216927,2987896214,906191..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scraping**\n",
    "\n",
    "Here are some versatile tools for pulling down information from the Web. Also, we will have a look at some other data sources that cannot really be counted as *social media* per se."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For starters, we have mature tools for parsing HTML (XML broadly speaking). Here is **lxml**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The yoozhe\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we are going to grab some html\n",
    "import lxml.html as lh\n",
    "\n",
    "# Simply way to make HTTP requests\n",
    "import requests\n",
    "\n",
    "URL = \"https://en.wikipedia.org/wiki/HTML\"\n",
    "r = requests.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we take the response and turn it into an *element tree*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree   = lh.fromstring(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get information by using the structure of the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HTML - Wikipedia'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.findtext('head/title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we can explore the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element head at 0x7f039b921b38>, <Element body at 0x7f039b921cc8>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "childs = tree.xpath('child::*')\n",
    "childs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second child is the body of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject page-HTML rootpage-HTML skin-vector action-view'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "body = childs[1]\n",
    "\n",
    "body.attrib['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look for all div elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "divList = body.xpath('div')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder what is in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mw-page-base', 'noprint']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divList[0].values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(divList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that many, we must have meant *find all of them*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDivs = body.xpath('//div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allDivs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wonder whether there are any interesting tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "allTables = body.xpath('//table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allTables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/QQeZcZL.gif\" style=\"width: 200px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infobox', 'width:22em']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = allTables[0]\n",
    "table.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not much information. What else is in there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table[1].xpath('tr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is a table with many rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't any structured datasets available in this page (just inspect). OK. Let's try another page from which we can pull some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://en.wikipedia.org/wiki/Python_(programming_language)\"\n",
    "p = requests.get(URL)\n",
    "\n",
    "ptree = lh.fromstring(p.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the source, we know what we are looking for. We can select by attribute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pTables = ptree.xpath(\"//table[@class='wikitable']\")\n",
    "len(pTables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we've got here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element caption at 0x7f039b92def8>, <Element tbody at 0x7f039b92df98>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chart = pTables[0]\n",
    "chart.xpath('child::*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastBody = chart[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lastBody.xpath('tr'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Let's build a `DataFrame` that represents the data in the table stored (and parsed as a tree) in `lastBody`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Type', 'mutable', 'Description', 'Syntax example'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toNP = [[x.text_content().strip() for x in r.xpath('th')] for r in lastBody.xpath('tr') ]\n",
    "toNP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that's not exactly what we expected, but it got the first row, so we can go ahead and use that for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Type', 'mutable', 'Description', 'Syntax example']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableCols = toNP[0]\n",
    "tableCols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how to get the remaining data? Let's redo that list comprehension. There is no way around it; we need a helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableHelper(node):\n",
    "    if len(node.xpath('code')) > 0:\n",
    "        codes = node.xpath('code')\n",
    "        txtCodes = ' '.join([x.text_content().strip() for x in codes])\n",
    "        return txtCodes\n",
    "    else:\n",
    "        return node.text_content().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the changes below. We are lookin in different tags (`td`) because that is where the data are. We have inserted our helper function in order to process the nodes properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bool', 'immutable', 'Boolean value', 'True False'],\n",
       " ['bytearray',\n",
       "  'mutable',\n",
       "  'Sequence of bytes',\n",
       "  'bytearray(b\\'Some ASCII\\') bytearray(b\"Some ASCII\") bytearray([119, 105, 107, 105])'],\n",
       " ['bytes',\n",
       "  'immutable',\n",
       "  'Sequence of bytes',\n",
       "  'b\\'Some ASCII\\' b\"Some ASCII\" bytes([119, 105, 107, 105])'],\n",
       " ['complex',\n",
       "  'immutable',\n",
       "  'Complex number with real and imaginary parts',\n",
       "  '3+2.7j'],\n",
       " ['dict',\n",
       "  'mutable',\n",
       "  'Associative array (or dictionary) of key and value pairs; can contain mixed types (keys and values), keys must be a hashable type',\n",
       "  \"{'key1': 1.0, 3: False}\"],\n",
       " ['ellipsis',\n",
       "  '',\n",
       "  'An ellipsis placeholder to be used as an index in NumPy arrays',\n",
       "  '...'],\n",
       " ['float',\n",
       "  'immutable',\n",
       "  'Floating point number, system-defined precision',\n",
       "  '3.1415927'],\n",
       " ['frozenset',\n",
       "  'immutable',\n",
       "  'Unordered set, contains no duplicates; can contain mixed types, if hashable',\n",
       "  \"frozenset([4.0, 'string', True])\"],\n",
       " ['int', 'immutable', 'Integer of unlimited magnitude[80]', '42'],\n",
       " ['list', 'mutable', 'List, can contain mixed types', \"[4.0, 'string', True]\"],\n",
       " ['set',\n",
       "  'mutable',\n",
       "  'Unordered set, contains no duplicates; can contain mixed types, if hashable',\n",
       "  \"{4.0, 'string', True}\"],\n",
       " ['str',\n",
       "  'immutable',\n",
       "  'A character string: sequence of Unicode codepoints',\n",
       "  '\\'Wikipedia\\' \"Wikipedia\" \"\"\"Spanningmultiplelines\"\"\"'],\n",
       " ['tuple', 'immutable', 'Can contain mixed types', \"(4.0, 'string', True)\"]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toNP = [[tableHelper(x) for x in r.xpath('td')] for r in lastBody.xpath('tr')[1:] ]\n",
    "toNP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is imperfect, but did we at least get the basic structure right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], 13)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(toNP), [len(x) for x in toNP], len([len(x) for x in toNP])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, everything has the right shape. Now let's build an `array` of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 4)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableData = np.array(toNP)\n",
    "tableData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, now let's build `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>mutable</th>\n",
       "      <th>Description</th>\n",
       "      <th>Syntax example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bool</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Boolean value</td>\n",
       "      <td>True False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bytearray</td>\n",
       "      <td>mutable</td>\n",
       "      <td>Sequence of bytes</td>\n",
       "      <td>bytearray(b'Some ASCII') bytearray(b\"Some ASCI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bytes</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Sequence of bytes</td>\n",
       "      <td>b'Some ASCII' b\"Some ASCII\" bytes([119, 105, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complex</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Complex number with real and imaginary parts</td>\n",
       "      <td>3+2.7j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dict</td>\n",
       "      <td>mutable</td>\n",
       "      <td>Associative array (or dictionary) of key and v...</td>\n",
       "      <td>{'key1': 1.0, 3: False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ellipsis</td>\n",
       "      <td></td>\n",
       "      <td>An ellipsis placeholder to be used as an index...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>float</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Floating point number, system-defined precision</td>\n",
       "      <td>3.1415927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>frozenset</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Unordered set, contains no duplicates; can con...</td>\n",
       "      <td>frozenset([4.0, 'string', True])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>int</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Integer of unlimited magnitude[80]</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>list</td>\n",
       "      <td>mutable</td>\n",
       "      <td>List, can contain mixed types</td>\n",
       "      <td>[4.0, 'string', True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>set</td>\n",
       "      <td>mutable</td>\n",
       "      <td>Unordered set, contains no duplicates; can con...</td>\n",
       "      <td>{4.0, 'string', True}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>str</td>\n",
       "      <td>immutable</td>\n",
       "      <td>A character string: sequence of Unicode codepo...</td>\n",
       "      <td>'Wikipedia' \"Wikipedia\" \"\"\"Spanningmultiplelin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tuple</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Can contain mixed types</td>\n",
       "      <td>(4.0, 'string', True)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type    mutable                                        Description  \\\n",
       "0        bool  immutable                                      Boolean value   \n",
       "1   bytearray    mutable                                  Sequence of bytes   \n",
       "2       bytes  immutable                                  Sequence of bytes   \n",
       "3     complex  immutable       Complex number with real and imaginary parts   \n",
       "4        dict    mutable  Associative array (or dictionary) of key and v...   \n",
       "5    ellipsis             An ellipsis placeholder to be used as an index...   \n",
       "6       float  immutable    Floating point number, system-defined precision   \n",
       "7   frozenset  immutable  Unordered set, contains no duplicates; can con...   \n",
       "8         int  immutable                 Integer of unlimited magnitude[80]   \n",
       "9        list    mutable                      List, can contain mixed types   \n",
       "10        set    mutable  Unordered set, contains no duplicates; can con...   \n",
       "11        str  immutable  A character string: sequence of Unicode codepo...   \n",
       "12      tuple  immutable                            Can contain mixed types   \n",
       "\n",
       "                                       Syntax example  \n",
       "0                                          True False  \n",
       "1   bytearray(b'Some ASCII') bytearray(b\"Some ASCI...  \n",
       "2   b'Some ASCII' b\"Some ASCII\" bytes([119, 105, 1...  \n",
       "3                                              3+2.7j  \n",
       "4                             {'key1': 1.0, 3: False}  \n",
       "5                                                 ...  \n",
       "6                                           3.1415927  \n",
       "7                    frozenset([4.0, 'string', True])  \n",
       "8                                                  42  \n",
       "9                               [4.0, 'string', True]  \n",
       "10                              {4.0, 'string', True}  \n",
       "11  'Wikipedia' \"Wikipedia\" \"\"\"Spanningmultiplelin...  \n",
       "12                              (4.0, 'string', True)  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableFrame = pd.DataFrame(data=tableData, columns=tableCols)\n",
    "tableFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is of course, room for improvement. Generally, when engaged in a scraping endeavor you will be interested in a specific kind of element in a specific kind of web page and therefore you will specialize your processing steps in order to clean things up. This is necessary; no amount of 'wrapping' or elegance will free us from having to express what we mean. That said, let's do some wrapping and also make use of some pre-packaged wrapping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I am going to put everything into a single function `getFrame`. My function *takes a string* and it *returns a `DataFrame`*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from above for completeness of this cell.\n",
    "def tableHelper(node):\n",
    "    if len(node.xpath('code')) > 0:\n",
    "        codes = node.xpath('code')\n",
    "        txtCodes = ' '.join([x.text_content().strip() for x in codes])\n",
    "        return txtCodes\n",
    "    else:\n",
    "        return node.text_content().strip()\n",
    "\n",
    "def getFrame(name):\n",
    "    \"\"\" Give me your thing\n",
    "    that you want me to \n",
    "    Wikipedia and I will\n",
    "    try to extract the first\n",
    "    table from it.\"\"\"\n",
    "    # Request and results\n",
    "    base = \"https://en.wikipedia.org/wiki/\"\n",
    "    URL = base+name\n",
    "    r = requests.get(URL)\n",
    "    # Prepare my element tree structure\n",
    "    tree   = lh.fromstring(r.text)\n",
    "    \n",
    "    # Finding the table\n",
    "    pTables = tree.xpath(\"//table[@class='wikitable']\")\n",
    "    Body = pTables[0].xpath('tbody')[0]\n",
    "\n",
    "    # Extracting the data\n",
    "    toNP = [[tableHelper(x) for x in r.xpath('td')] for r in Body.xpath('tr')[1:] ]\n",
    "    tableData = np.array(toNP)\n",
    "    \n",
    "    # Extracting the column names\n",
    "    header = Body.xpath('tr')[0]\n",
    "    tableCols = [x.text_content().strip() for x in header.xpath('th')]\n",
    "    \n",
    "    # Building the DataFrame\n",
    "    tableFrame = pd.DataFrame(data=tableData, columns=tableCols)\n",
    "    \n",
    "    return tableFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year ending</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Pre-tax profit</th>\n",
       "      <th>Production</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31 July 2002</td>\n",
       "      <td>€4,857m</td>\n",
       "      <td>€829m</td>\n",
       "      <td>55,050</td>\n",
       "      <td>54,234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31 July 2003</td>\n",
       "      <td>€5,583m</td>\n",
       "      <td>€933m</td>\n",
       "      <td>73,284</td>\n",
       "      <td>66,803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31 July 2004</td>\n",
       "      <td>€6,148m</td>\n",
       "      <td>€1,137m</td>\n",
       "      <td>81,531</td>\n",
       "      <td>76,827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31 July 2005</td>\n",
       "      <td>€6,574m</td>\n",
       "      <td>€1,238m</td>\n",
       "      <td>90,954</td>\n",
       "      <td>88,379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31 July 2006</td>\n",
       "      <td>€7,273m</td>\n",
       "      <td>€2,110m</td>\n",
       "      <td>102,602</td>\n",
       "      <td>96,794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31 July 2007</td>\n",
       "      <td>€7,368m</td>\n",
       "      <td>€5,857m</td>\n",
       "      <td>101,844</td>\n",
       "      <td>97,515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31 July 2008</td>\n",
       "      <td>€7,466m</td>\n",
       "      <td>€8,569m</td>\n",
       "      <td>105,162</td>\n",
       "      <td>98,652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31 July 2009</td>\n",
       "      <td>€?m</td>\n",
       "      <td>€-2,559m</td>\n",
       "      <td>76,739</td>\n",
       "      <td>75,238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31 July 2010</td>\n",
       "      <td>€7.79b</td>\n",
       "      <td>N/A</td>\n",
       "      <td>89,123</td>\n",
       "      <td>81,850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31 December 2010</td>\n",
       "      <td>€9.23b</td>\n",
       "      <td>€1.67b[39]</td>\n",
       "      <td>N/A</td>\n",
       "      <td>97,273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>31 December 2011[39]</td>\n",
       "      <td>€10.9b</td>\n",
       "      <td>€2.05b</td>\n",
       "      <td>127,793</td>\n",
       "      <td>116,978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31 December 2012</td>\n",
       "      <td>€13.9b</td>\n",
       "      <td>€2.44b</td>\n",
       "      <td>151,999</td>\n",
       "      <td>143,096[40]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>31 December 2013</td>\n",
       "      <td>€14.3b</td>\n",
       "      <td>€2.78b</td>\n",
       "      <td>165,808</td>\n",
       "      <td>162,145[41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>31 December 2014</td>\n",
       "      <td>€17.2b</td>\n",
       "      <td>€3.06b</td>\n",
       "      <td>203,097</td>\n",
       "      <td>187,208[42]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>31 December 2015</td>\n",
       "      <td>€21.5b[43]</td>\n",
       "      <td>€3.382b</td>\n",
       "      <td>234,497</td>\n",
       "      <td>225,121[44]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Year ending     Revenue Pre-tax profit Production        Sales\n",
       "0           31 July 2002     €4,857m          €829m     55,050       54,234\n",
       "1           31 July 2003     €5,583m          €933m     73,284       66,803\n",
       "2           31 July 2004     €6,148m        €1,137m     81,531       76,827\n",
       "3           31 July 2005     €6,574m        €1,238m     90,954       88,379\n",
       "4           31 July 2006     €7,273m        €2,110m    102,602       96,794\n",
       "5           31 July 2007     €7,368m        €5,857m    101,844       97,515\n",
       "6           31 July 2008     €7,466m        €8,569m    105,162       98,652\n",
       "7           31 July 2009         €?m       €-2,559m     76,739       75,238\n",
       "8           31 July 2010      €7.79b            N/A     89,123       81,850\n",
       "9       31 December 2010      €9.23b     €1.67b[39]        N/A       97,273\n",
       "10  31 December 2011[39]      €10.9b         €2.05b    127,793      116,978\n",
       "11      31 December 2012      €13.9b         €2.44b    151,999  143,096[40]\n",
       "12      31 December 2013      €14.3b         €2.78b    165,808  162,145[41]\n",
       "13      31 December 2014      €17.2b         €3.06b    203,097  187,208[42]\n",
       "14      31 December 2015  €21.5b[43]        €3.382b    234,497  225,121[44]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newFrame = getFrame('porsche')\n",
    "newFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** (for the reader)\n",
    "1. Make this function more robust against errors/incompatible pages\n",
    "2. Make this function more fully-featured (w.r.t input)\n",
    "3. Make this function more refined (w.r.t output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are existing tools for parsing web pages. Let's have a look at *Beautiful Soup*, named for *tag soup* - a term of endearment for messy HTML or XML. The `lxml` [documentation](https://lxml.de/) mentions Beautiful Soup as an alternative for handling *really broken* HTML documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "#mw-head\n",
      "#p-search\n",
      "/wiki/Wikipedia\n",
      "/wiki/Free_content\n",
      "/wiki/Encyclopedia\n",
      "/wiki/Wikipedia:Introduction\n",
      "/wiki/Special:Statistics\n",
      "/wiki/English_language\n",
      "/wiki/Portal:Arts\n",
      "/wiki/Portal:Biography\n",
      "/wiki/Portal:Geography\n",
      "/wiki/Portal:History\n",
      "/wiki/Portal:Mathematics\n",
      "/wiki/Portal:Science\n",
      "/wiki/Portal:Society\n",
      "/wiki/Portal:Technology\n",
      "/wiki/Portal:Contents/Portals\n",
      "/wiki/File:Camille_Saint-Sa%C3%ABns_in_1900_by_Pierre_Petit.jpg\n",
      "/wiki/Camille_Saint-Sa%C3%ABns\n",
      "/wiki/Romantic_music\n",
      "/wiki/Danse_macabre_(Saint-Sa%C3%ABns)\n",
      "/wiki/Samson_and_Delilah_(opera)\n",
      "/wiki/Symphony_No._3_(Saint-Sa%C3%ABns)\n",
      "/wiki/The_Carnival_of_the_Animals\n",
      "/wiki/Paris_Conservatoire\n",
      "/wiki/Saint-Merri\n",
      "/wiki/La_Madeleine,_Paris\n",
      "/wiki/Second_French_Empire\n",
      "/wiki/Robert_Schumann\n",
      "/wiki/Franz_Liszt\n",
      "/wiki/Richard_Wagner\n",
      "/wiki/Impressionism_in_music\n",
      "/wiki/Dodecaphonic\n",
      "/wiki/Camille_Saint-Sa%C3%ABns\n",
      "/wiki/Mark_Oliphant\n",
      "/wiki/Francis_Nash\n",
      "/wiki/Tree_swallow\n",
      "/wiki/Wikipedia:Today%27s_featured_article/October_2018\n",
      "https://lists.wikimedia.org/mailman/listinfo/daily-article-l\n",
      "/wiki/Wikipedia:Featured_articles\n",
      "/wiki/File:SA_Sturm_Cigarette_Company_ad.jpg\n",
      "/wiki/Anti-tobacco_movement_in_Nazi_Germany\n",
      "/wiki/Sturmabteilung\n",
      "/wiki/Sturm_Cigarette_Company\n",
      "/wiki/Luxembourg\n",
      "/wiki/Association_football\n",
      "/wiki/Sanel_Ibrahimovi%C4%87\n",
      "/wiki/Bosnia_and_Herzegovina_cuisine\n",
      "/wiki/La_Belle_et_la_B%C3%AAte_(opera)\n",
      "/wiki/Philip_Glass\n",
      "/wiki/Beauty_and_the_Beast_(1946_film)\n",
      "/wiki/Jean_Cocteau\n",
      "/wiki/Rose_Connor\n",
      "/wiki/Women_in_architecture\n",
      "/wiki/Mitochondrial_DNA\n",
      "/wiki/Medusozoa\n",
      "/wiki/Maya_Krishna_Rao\n",
      "/wiki/Sangeet_Natak_Akademi_Award\n",
      "/wiki/Soulard_Farmers_Market\n",
      "/wiki/Marketplace\n",
      "/wiki/Mississippi_River\n",
      "/wiki/Kolya_Vasin\n",
      "/wiki/Saint_Petersburg\n",
      "/wiki/John_Lennon\n",
      "/wiki/Wikipedia:Recent_additions\n",
      "/wiki/Wikipedia:Your_first_article\n",
      "/wiki/Template_talk:Did_you_know\n",
      "/wiki/File:Paul_Romer_in_2005.jpg\n",
      "/wiki/Nobel_Memorial_Prize_in_Economic_Sciences\n",
      "/wiki/William_Nordhaus\n",
      "/wiki/Paul_Romer\n",
      "/wiki/Climate_change\n",
      "/wiki/Technological_innovation\n",
      "/wiki/Economic_growth\n",
      "/wiki/Meng_Hongwei\n",
      "/wiki/Interpol\n",
      "/wiki/National_Supervisory_Commission\n",
      "/wiki/43rd_Chess_Olympiad\n",
      "/wiki/Open_event_at_the_43rd_Chess_Olympiad\n",
      "/wiki/Women%27s_event_at_the_43rd_Chess_Olympiad\n",
      "/wiki/Denis_Mukwege\n",
      "/wiki/Nadia_Murad\n",
      "/wiki/Nobel_Peace_Prize\n",
      "/wiki/Sexual_violence\n",
      "/wiki/Deaths_in_2018\n",
      "/wiki/Natwar_Thakkar\n",
      "/wiki/Montserrat_Caball%C3%A9\n",
      "/wiki/Dave_Anderson_(sportswriter)\n",
      "/wiki/Marty_Pattin\n",
      "/wiki/Portal:Current_events\n",
      "/wiki/Wikipedia:In_the_news/Candidates\n",
      "/wiki/October_9\n",
      "/wiki/Leif_Erikson_Day\n",
      "/wiki/File:Washington_Monument_Dusk_Jan_2006.jpg\n",
      "/wiki/1594\n",
      "/wiki/Sinhalese%E2%80%93Portuguese_War\n",
      "/wiki/Campaign_of_Danture\n",
      "/wiki/1708\n",
      "/wiki/Great_Northern_War\n",
      "/wiki/Battle_of_Lesnaya\n",
      "/wiki/1888\n",
      "/wiki/Washington_Monument\n",
      "/wiki/Washington,_D.C.\n",
      "/wiki/List_of_tallest_buildings_and_structures\n",
      "/wiki/1914\n",
      "/wiki/World_War_I\n",
      "/wiki/Antwerp\n",
      "/wiki/Siege_of_Antwerp_(1914)\n",
      "/wiki/2016\n",
      "/wiki/Northern_Rakhine_State_clashes#2016\n",
      "/wiki/Myanmar\n",
      "/wiki/2016_Rohingya_persecution_in_Myanmar\n",
      "/wiki/Henry_Constable\n",
      "/wiki/Benjamin_Banneker\n",
      "/wiki/Mona_Best\n",
      "/wiki/October_8\n",
      "/wiki/October_9\n",
      "/wiki/October_10\n",
      "/wiki/Wikipedia:Selected_anniversaries/October\n",
      "https://lists.wikimedia.org/mailman/listinfo/daily-article-l\n",
      "/wiki/List_of_historical_anniversaries\n",
      "/wiki/File:Madonna_Haller.jpg\n",
      "/wiki/Haller_Madonna\n",
      "/wiki/Oil_painting\n",
      "/wiki/Albrecht_D%C3%BCrer\n",
      "/wiki/National_Gallery_of_Art\n",
      "/wiki/Mary,_mother_of_Jesus\n",
      "/wiki/Jesus\n",
      "/wiki/Giovanni_Bellini\n",
      "/wiki/Venice\n",
      "/wiki/Nuremberg\n",
      "/wiki/Haller_von_Hallerstein\n",
      "/wiki/Koberger\n",
      "/wiki/Template:POTD/2018-10-09/2\n",
      "/wiki/Lot_(biblical_figure)\n",
      "/wiki/Sodom_and_Gomorrah\n",
      "/wiki/Albrecht_D%C3%BCrer\n",
      "/wiki/Template:POTD/2018-10-08\n",
      "/wiki/Template:POTD/2018-10-07\n",
      "/wiki/Template:POTD/2018-10-06\n",
      "/wiki/Wikipedia:Picture_of_the_day/October_2018\n",
      "/wiki/Wikipedia:Featured_pictures\n",
      "/wiki/Wikipedia:Community_portal\n",
      "/wiki/Wikipedia:Help_desk\n",
      "/wiki/Wikipedia:Local_Embassy\n",
      "/wiki/Wikipedia:Reference_desk\n",
      "/wiki/Wikipedia:News\n",
      "/wiki/Wikipedia:Village_pump\n",
      "/wiki/Wikimedia_Foundation\n",
      "https://foundation.wikimedia.org/wiki/Our_projects\n",
      "https://commons.wikimedia.org/wiki/\n",
      "//commons.wikimedia.org/\n",
      "https://www.mediawiki.org/wiki/\n",
      "//mediawiki.org/\n",
      "https://meta.wikimedia.org/wiki/\n",
      "//meta.wikimedia.org/\n",
      "https://en.wikibooks.org/wiki/\n",
      "//en.wikibooks.org/\n",
      "https://www.wikidata.org/wiki/\n",
      "//www.wikidata.org/\n",
      "https://en.wikinews.org/wiki/\n",
      "//en.wikinews.org/\n",
      "https://en.wikiquote.org/wiki/\n",
      "//en.wikiquote.org/\n",
      "https://en.wikisource.org/wiki/\n",
      "//en.wikisource.org/\n",
      "https://species.wikimedia.org/wiki/\n",
      "//species.wikimedia.org/\n",
      "https://en.wikiversity.org/wiki/\n",
      "//en.wikiversity.org/\n",
      "https://en.wikivoyage.org/wiki/\n",
      "//en.wikivoyage.org/\n",
      "https://en.wiktionary.org/wiki/\n",
      "//en.wiktionary.org/\n",
      "/wiki/English_language\n",
      "/wiki/Special:Statistics\n",
      "https://de.wikipedia.org/wiki/\n",
      "https://es.wikipedia.org/wiki/\n",
      "https://fr.wikipedia.org/wiki/\n",
      "https://it.wikipedia.org/wiki/\n",
      "https://nl.wikipedia.org/wiki/\n",
      "https://ja.wikipedia.org/wiki/\n",
      "https://pl.wikipedia.org/wiki/\n",
      "https://pt.wikipedia.org/wiki/\n",
      "https://ru.wikipedia.org/wiki/\n",
      "https://sv.wikipedia.org/wiki/\n",
      "https://vi.wikipedia.org/wiki/\n",
      "https://zh.wikipedia.org/wiki/\n",
      "https://ar.wikipedia.org/wiki/\n",
      "https://id.wikipedia.org/wiki/\n",
      "https://ms.wikipedia.org/wiki/\n",
      "https://ca.wikipedia.org/wiki/\n",
      "https://cs.wikipedia.org/wiki/\n",
      "https://eo.wikipedia.org/wiki/\n",
      "https://eu.wikipedia.org/wiki/\n",
      "https://fa.wikipedia.org/wiki/\n",
      "https://ko.wikipedia.org/wiki/\n",
      "https://hu.wikipedia.org/wiki/\n",
      "https://no.wikipedia.org/wiki/\n",
      "https://ro.wikipedia.org/wiki/\n",
      "https://sr.wikipedia.org/wiki/\n",
      "https://sh.wikipedia.org/wiki/\n",
      "https://fi.wikipedia.org/wiki/\n",
      "https://tr.wikipedia.org/wiki/\n",
      "https://uk.wikipedia.org/wiki/\n",
      "https://bs.wikipedia.org/wiki/\n",
      "https://bg.wikipedia.org/wiki/\n",
      "https://da.wikipedia.org/wiki/\n",
      "https://et.wikipedia.org/wiki/\n",
      "https://el.wikipedia.org/wiki/\n",
      "https://simple.wikipedia.org/wiki/\n",
      "https://gl.wikipedia.org/wiki/\n",
      "https://he.wikipedia.org/wiki/\n",
      "https://hr.wikipedia.org/wiki/\n",
      "https://lv.wikipedia.org/wiki/\n",
      "https://lt.wikipedia.org/wiki/\n",
      "https://ml.wikipedia.org/wiki/\n",
      "https://nn.wikipedia.org/wiki/\n",
      "https://sk.wikipedia.org/wiki/\n",
      "https://sl.wikipedia.org/wiki/\n",
      "https://th.wikipedia.org/wiki/\n",
      "https://meta.wikimedia.org/wiki/List_of_Wikipedias\n",
      "https://en.wikipedia.org/w/index.php?title=Main_Page&oldid=847600508\n",
      "/wiki/Special:MyTalk\n",
      "/wiki/Special:MyContributions\n",
      "/w/index.php?title=Special:CreateAccount&returnto=Main+Page\n",
      "/w/index.php?title=Special:UserLogin&returnto=Main+Page\n",
      "/wiki/Main_Page\n",
      "/wiki/Talk:Main_Page\n",
      "/wiki/Main_Page\n",
      "/w/index.php?title=Main_Page&action=edit\n",
      "/w/index.php?title=Main_Page&action=history\n",
      "/wiki/Main_Page\n",
      "/wiki/Main_Page\n",
      "/wiki/Portal:Contents\n",
      "/wiki/Portal:Featured_content\n",
      "/wiki/Portal:Current_events\n",
      "/wiki/Special:Random\n",
      "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&utm_medium=sidebar&utm_campaign=C13_en.wikipedia.org&uselang=en\n",
      "//shop.wikimedia.org\n",
      "/wiki/Help:Contents\n",
      "/wiki/Wikipedia:About\n",
      "/wiki/Wikipedia:Community_portal\n",
      "/wiki/Special:RecentChanges\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "/wiki/Special:WhatLinksHere/Main_Page\n",
      "/wiki/Special:RecentChangesLinked/Main_Page\n",
      "/wiki/Wikipedia:File_Upload_Wizard\n",
      "/wiki/Special:SpecialPages\n",
      "/w/index.php?title=Main_Page&oldid=847600508\n",
      "/w/index.php?title=Main_Page&action=info\n",
      "https://www.wikidata.org/wiki/Special:EntityPage/Q5296\n",
      "/w/index.php?title=Special:CiteThisPage&page=Main_Page&id=847600508\n",
      "/w/index.php?title=Special:Book&bookcmd=book_creator&referer=Main+Page\n",
      "/w/index.php?title=Special:ElectronPdf&page=Main+Page&action=show-download-screen\n",
      "/w/index.php?title=Main_Page&printable=yes\n",
      "https://commons.wikimedia.org/wiki/Main_Page\n",
      "https://www.mediawiki.org/wiki/MediaWiki\n",
      "https://meta.wikimedia.org/wiki/Main_Page\n",
      "https://species.wikimedia.org/wiki/Main_Page\n",
      "https://en.wikibooks.org/wiki/Main_Page\n",
      "https://www.wikidata.org/wiki/Wikidata:Main_Page\n",
      "https://en.wikinews.org/wiki/Main_Page\n",
      "https://en.wikiquote.org/wiki/Main_Page\n",
      "https://en.wikisource.org/wiki/Main_Page\n",
      "https://en.wikiversity.org/wiki/Wikiversity:Main_Page\n",
      "https://en.wikivoyage.org/wiki/Main_Page\n",
      "https://en.wiktionary.org/wiki/Wiktionary:Main_Page\n",
      "https://ar.wikipedia.org/wiki/\n",
      "https://bg.wikipedia.org/wiki/\n",
      "https://bs.wikipedia.org/wiki/\n",
      "https://ca.wikipedia.org/wiki/\n",
      "https://cs.wikipedia.org/wiki/\n",
      "https://da.wikipedia.org/wiki/\n",
      "https://de.wikipedia.org/wiki/\n",
      "https://et.wikipedia.org/wiki/\n",
      "https://el.wikipedia.org/wiki/\n",
      "https://es.wikipedia.org/wiki/\n",
      "https://eo.wikipedia.org/wiki/\n",
      "https://eu.wikipedia.org/wiki/\n",
      "https://fa.wikipedia.org/wiki/\n",
      "https://fr.wikipedia.org/wiki/\n",
      "https://gl.wikipedia.org/wiki/\n",
      "https://ko.wikipedia.org/wiki/\n",
      "https://hr.wikipedia.org/wiki/\n",
      "https://id.wikipedia.org/wiki/\n",
      "https://it.wikipedia.org/wiki/\n",
      "https://he.wikipedia.org/wiki/\n",
      "https://ka.wikipedia.org/wiki/\n",
      "https://lv.wikipedia.org/wiki/\n",
      "https://lt.wikipedia.org/wiki/\n",
      "https://hu.wikipedia.org/wiki/\n",
      "https://ms.wikipedia.org/wiki/\n",
      "https://nl.wikipedia.org/wiki/\n",
      "https://ja.wikipedia.org/wiki/\n",
      "https://no.wikipedia.org/wiki/\n",
      "https://nn.wikipedia.org/wiki/\n",
      "https://pl.wikipedia.org/wiki/\n",
      "https://pt.wikipedia.org/wiki/\n",
      "https://ro.wikipedia.org/wiki/\n",
      "https://ru.wikipedia.org/wiki/\n",
      "https://simple.wikipedia.org/wiki/\n",
      "https://sk.wikipedia.org/wiki/\n",
      "https://sl.wikipedia.org/wiki/\n",
      "https://sr.wikipedia.org/wiki/\n",
      "https://sh.wikipedia.org/wiki/\n",
      "https://fi.wikipedia.org/wiki/\n",
      "https://sv.wikipedia.org/wiki/\n",
      "https://th.wikipedia.org/wiki/\n",
      "https://tr.wikipedia.org/wiki/\n",
      "https://uk.wikipedia.org/wiki/\n",
      "https://vi.wikipedia.org/wiki/\n",
      "https://zh.wikipedia.org/wiki/\n",
      "//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License\n",
      "//creativecommons.org/licenses/by-sa/3.0/\n",
      "//foundation.wikimedia.org/wiki/Terms_of_Use\n",
      "//foundation.wikimedia.org/wiki/Privacy_policy\n",
      "//www.wikimediafoundation.org/\n",
      "https://foundation.wikimedia.org/wiki/Privacy_policy\n",
      "/wiki/Wikipedia:About\n",
      "/wiki/Wikipedia:General_disclaimer\n",
      "//en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
      "https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\n",
      "https://foundation.wikimedia.org/wiki/Cookie_statement\n",
      "//en.m.wikipedia.org/w/index.php?title=Main_Page&mobileaction=toggle_view_mobile\n",
      "https://wikimediafoundation.org/\n",
      "//www.mediawiki.org/\n"
     ]
    }
   ],
   "source": [
    "# Example from the Wikipedia page on BS4\n",
    "# Note the use of the native urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "with urllib.request.urlopen('https://en.wikipedia.org/wiki/Main_Page') as response:\n",
    "    webpage = response.read()\n",
    "    soup = BeautifulSoup(webpage, 'html.parser')\n",
    "    for anchor in soup.find_all('a'):\n",
    "        print(anchor.get('href', '/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to replicate what we did above, this time using `bs4`. The setup is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://en.wikipedia.org/wiki/\" \n",
    "URL = base+\"Python_(programming_language)\"\n",
    "r = requests.get(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we parse the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text)\n",
    "table = soup.findAll('table',{'class':'wikitable'})[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, the rest of this goes pretty much as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Type'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustration of the methods we're using\n",
    "header = table.findAll('th')[0]\n",
    "header.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recreate that list comprehension from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "toNP = [[x.text.strip() for x in r.findAll('th')] for r in table.findAll('tr') ]\n",
    "tableCols = toNP[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should probably rewrite `tableHelper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableHelper(node):\n",
    "    if len(node.findAll('code')) > 0:\n",
    "        codes = node.findAll('code')\n",
    "        txtCodes = ' '.join([x.text.strip() for x in codes])\n",
    "        return txtCodes\n",
    "    else:\n",
    "        return node.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "toNP = [[tableHelper(x) for x in r.findAll('td')] for r in table.findAll('tr')[1:] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>mutable</th>\n",
       "      <th>Description</th>\n",
       "      <th>Syntax example</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bool</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Boolean value</td>\n",
       "      <td>True False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bytearray</td>\n",
       "      <td>mutable</td>\n",
       "      <td>Sequence of bytes</td>\n",
       "      <td>bytearray(b'Some ASCII') bytearray(b\"Some ASCI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bytes</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Sequence of bytes</td>\n",
       "      <td>b'Some ASCII' b\"Some ASCII\" bytes([119, 105, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>complex</td>\n",
       "      <td>immutable</td>\n",
       "      <td>Complex number with real and imaginary parts</td>\n",
       "      <td>3+2.7j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dict</td>\n",
       "      <td>mutable</td>\n",
       "      <td>Associative array (or dictionary) of key and v...</td>\n",
       "      <td>{'key1': 1.0, 3: False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Type    mutable                                        Description  \\\n",
       "0       bool  immutable                                      Boolean value   \n",
       "1  bytearray    mutable                                  Sequence of bytes   \n",
       "2      bytes  immutable                                  Sequence of bytes   \n",
       "3    complex  immutable       Complex number with real and imaginary parts   \n",
       "4       dict    mutable  Associative array (or dictionary) of key and v...   \n",
       "\n",
       "                                      Syntax example  \n",
       "0                                         True False  \n",
       "1  bytearray(b'Some ASCII') bytearray(b\"Some ASCI...  \n",
       "2  b'Some ASCII' b\"Some ASCII\" bytes([119, 105, 1...  \n",
       "3                                             3+2.7j  \n",
       "4                            {'key1': 1.0, 3: False}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableData = np.array(toNP)\n",
    "tableFrame = pd.DataFrame(data=tableData, columns=tableCols)\n",
    "tableFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief illustration of the options in parsing HTML responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"<a><b /></a>\"\n",
    "doc2 = \"<a></p>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `bs4` in a few different ways. Here we parse `doc1` as HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><a><b></b></a></body></html>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we parse the same document as XML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<a><b/></a>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(doc1,'xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the `lxml` library to parse the second, invalid document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><a></a></body></html>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(doc2, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `lxml` library decided to simple drop the dangling end tag. What will the `html5lib` library do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head></head><body><a><p></p></a></body></html>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BeautifulSoup(doc2,'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, this one filled in the missing start tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REGEX**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a brief look at *regular expressions*. This is another tool that will serve you well in wrangling real-world data, particularly text data. This discussion of scraping is as good a place as any for a review of regexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tedURL = \"https://www.washingtonpost.com/wp-srv/national/longterm/unabomber/manifesto.text.htm?noredirect=on\"\n",
    "tedMan = requests.get(tedURL)\n",
    "tedParags =  [x.text_content().strip() for x in lh.fromstring(tedMan.text).xpath('//p')]\n",
    "tedText = 'PARAG'.join(tedParags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We didn't really need that last part, it was just for fun. Now we have a really long string. Let's look for patterns in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">A regular expression (or RE) specifies a set of strings that matches it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the rest of the documentation [here](https://docs.python.org/3/library/re.html). Let's look at some examples. We inserted those \"PARAG\" strings. What follows them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example below uses a *lookahead* pattern - we don't extract the \"PARAG\", but the thing that follows it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Editor's Note: This is the text of a 35,000-word manifesto as submitted to The \",\n",
       " 'Return to our special report.PARAGPARAGPARAGIntroductionPARAG1. The Industrial Revolution and its consequences have been a disaster for the human race. They have ',\n",
       " '2. The industrial-technological system may survive or it may break down. If it survives, it MAY eventually ',\n",
       " '3. If the system breaks down the consequences will still be very painful. But the bigger the system grows the ',\n",
       " '4. We therefore advocate a revolution against the industrial system. This revolution may or may not make ',\n",
       " '5. In this article we give attention to only some of the negative developments that have grown out of the ',\n",
       " 'THE PSYCHOLOGY OF MODERN LEFTISMPARAG6. Almost everyone will agree that we live in a deeply troubled society. One of the most widespread ',\n",
       " '7. But what is leftism? During the first half of the 20th century leftism could have been practically identified ',\n",
       " '8. Even so, our conception of leftism will remain a good deal less clear than we would wish, but there ',\n",
       " '9. The two psychological tendencies that underlie modern leftism we call \\x93feelings of inferiority\\x94 and ',\n",
       " 'FEELINGS OF INFERIORITYPARAG10. By \\x93feelings of inferiority\\x94 we mean not only inferiority feelings in the strict sense but a whole spectrum ',\n",
       " '11. When someone interprets as derogatory almost anything that is said about him (or about groups with ',\n",
       " '12. Those who are most sensitive about \\x93politically incorrect\\x94 terminology are not the average black ghetto-',\n",
       " '13. Many leftists have an intense identification with the problems of groups that have an image of being ',\n",
       " '14. Feminists are desperately anxious to prove that women are as strong and as capable as men. Clearly they ',\n",
       " '15. Leftists tend to hate anything that has an image of being strong, good and successful. They hate ',\n",
       " '16. Words like \\x93self-confidence,\\x94 \\x93self-reliance,\\x94 \\x93initiative,\\x94 \\x93enterprise,\\x94 \\x93optimism,\\x94 etc., play little role ',\n",
       " '17. Art forms that appeal to modern leftish intellectuals tend to focus on sordidness, defeat and despair, or ',\n",
       " '18. Modern leftish philosophers tend to dismiss reason, science, objective reality and to insist that ',\n",
       " '19. The leftist is not typically the kind of person whose feelings of inferiority make him a braggart, an ',\n",
       " '20. Notice the masochistic tendency of leftist tactics. Leftists protest by lying down in front of vehicles, they ',\n",
       " '21. Leftists may claim that their activism is motivated by compassion or by moral principles, and moral ',\n",
       " '22. If our society had no social problems at all, the leftists would have to INVENT problems in order to ',\n",
       " '23. We emphasize that the foregoing does not pretend to be an accurate description of everyone who might ',\n",
       " 'OVERSOCIALIZATIONPARAG24. Psychologists use the term \\x93socialization\\x94 to designate the process by which children are trained to ',\n",
       " '25. The moral code of our society is so demanding that no one can think, feel and act in a completely moral ',\n",
       " '26. Oversocialization can lead to low self-esteem, a sense of powerlessness, defeatism, guilt, etc. One of the ',\n",
       " '27. We argue that a very important and influential segment of the modern left is oversocialized and that ',\n",
       " '28. The leftist of the oversocialized type tries to get off his psychological leash and assert his autonomy by ',\n",
       " '29. Here is an illustration of the way in which the oversocialized leftist shows his real attachment to the ',\n",
       " '30. We certainly do not claim that leftists, even of the oversocialized type, NEVER rebel against the ',\n",
       " '31. We realize that many objections could be raised to the foregoing thumbnail sketch of leftist psychology. ',\n",
       " '32. The problems of the leftist are indicative of the problems of our society as a whole. Low self-esteem, ',\n",
       " 'THE POWER PROCESSPARAG33. Human beings have a need (probably based in biology) for something that we will call the \\x93power ',\n",
       " '34. Consider the hypothetical case of a man who can have anything he wants just by wishing for it. Such a ',\n",
       " '35. Everyone has goals; if nothing else, to obtain the physical necessities of life: food, water and whatever ',\n",
       " '36. Nonattainment of important goals results in death if the goals are physical necessities, and in frustration ',\n",
       " '37, Thus, in order to avoid serious psychological problems, a human being needs goals whose attainment ',\n",
       " 'SURROGATE ACTIVITIESPARAG38. But not every leisured aristocrat becomes bored and demoralized. For example, the emperor Hirohito, ',\n",
       " '39. We use the term \\x93surrogate activity\\x94 to designate an activity that is directed toward an artificial goal that ',\n",
       " '40. In modern industrial society only minimal effort is necessary to satisfy one\\x92s physical needs. It is ',\n",
       " '41. For many if not most people, surrogate activities are less satisfying than the pursuit of real goals (that is, ',\n",
       " 'AUTONOMYPARAG42. Autonomy as a part of the power process may not be necessary for every individual. But most people ',\n",
       " '43. It is true that some individuals seem to have little need for autonomy. Either their drive for power is ',\n",
       " '44. But for most people it is through the power process\\x97having a goal, making an AUTONOMOUS effort ',\n",
       " 'SOURCES OF SOCIAL PROBLEMSPARAG45. Any of the foregoing symptoms can occur in any society, but in modern industrial society they are ',\n",
       " '46. We attribute the social and psychological problems of modern society to the fact that that society ',\n",
       " '47. Among the abnormal conditions present in modern industrial society are excessive density of ',\n",
       " '48. It is well known that crowding increases stress and aggression. The degree of crowding that exists today ',\n",
       " '49. For primitive societies the natural world (which usually changes only slowly) provided a stable ',\n",
       " '50. The conservatives are fools: They whine about the decay of traditional values, yet they enthusiastically ',\n",
       " '51. The breakdown of traditional values to some extent implies the breakdown of the bonds that hold ',\n",
       " '52. Suppose that a public official or a corporation executive appoints his cousin, his friend or his co-',\n",
       " '53. Crowding, rapid change and the breakdown of communities have been widely recognized as sources of ',\n",
       " '54. A few pre-industrial cities were very large and crowded, yet their inhabitants do not seem to have ',\n",
       " '55. On the growing edge of the American frontier during the 19th century, the mobility of the population ',\n",
       " '56. Furthermore, change in American frontier society was very rapid and deep. A man might be born and ',\n",
       " '57. The difference, we argue, is that modern man has the sense (largely justified) that change is IMPOSED ',\n",
       " '58. It would be possible to give other examples of societies in which there has been rapid change and/or ',\n",
       " 'DISRUPTION OF THE POWER PROCESS IN MODERN SOCIETYPARAG59. We divide human drives into three groups: (1) those drives that can be satisfied with minimal effort; (2) ',\n",
       " '60. In modern industrial society natural human drives tend to be pushed into the first and third groups, and ',\n",
       " '61. In primitive societies, physical necessities generally fall into group 2: They can be obtained, but only at ',\n",
       " '62. Social needs, such as sex, love and status, often remain in group 2 in modern society, depending on the ',\n",
       " '63. So certain artificial needs have been created that fall into group 2, hence serve the need for the power ',\n",
       " '64. It seems that for many people, maybe the majority, these artificial forms of the power process are ',\n",
       " '65. Moreover, where goals are pursued through earning money, climbing the status ladder or functioning as ',\n",
       " '66. Today people live more by virtue of what the system does FOR them or TO them than by virtue of what ',\n",
       " '67. Thus the power process is disrupted in our society through a deficiency of real goals and a deficiency of ',\n",
       " '68. It may be objected that primitive man is physically less secure than modern man, as is shown by his ',\n",
       " '69. It is true that primitive man is powerless against some of the things that threaten him; disease for ',\n",
       " '70. Thus primitive man for the most part has his security in his own hands (either as an individual or as a ',\n",
       " '71. People have many transitory drives or impulses that are necessarily frustrated in modern life, hence fall ',\n",
       " '72. Modern society is in certain respects extremely permissive. In matters that are irrelevant to the ',\n",
       " '73. Behavior is regulated not only through explicit rules and not only by the government. Control is often ',\n",
       " '74. We suggest that modern man\\x92s obsession with longevity, and with maintaining physical vigor and sexual ',\n",
       " '75. In primitive societies life is a succession of stages. The needs and purposes of one stage having been ',\n",
       " '76. In response to the arguments of this section someone will say, \\x93Society must find a way to give people ',\n",
       " 'HOW SOME PEOPLE ADJUSTPARAG77. Not everyone in industrial-technological society suffers from psychological problems. Some people ',\n",
       " '78. First, there doubtless are differences in the strength of the drive for power. Individuals with a weak ',\n",
       " '79. Some people may have some exceptional drive, in pursuing which they satisfy their need for the power ',\n",
       " '80. People vary in their susceptibility to advertising and marketing techniques. Some are so susceptible that, ',\n",
       " '81. Some people have low susceptibility to advertising and marketing techniques. These are the people who ',\n",
       " '82. People who have medium susceptibility to advertising and marketing techniques are able to earn enough ',\n",
       " '83. Some people partly satisfy their need for power by identifying themselves with a powerful organization ',\n",
       " '84. Another way in which people satisfy their need for the power process is through surrogate activities. As ',\n",
       " '85. In this section we have explained how many people in modern society do satisfy their need for the ',\n",
       " '86. But even if most people in industrial-technological society were well satisfied, we (FC) would still be ',\n",
       " 'THE MOTIVES OF SCIENTISTSPARAG87. Science and technology provide the most important examples of surrogate activities. Some scientists ',\n",
       " '88. The \\x93benefit of humanity\\x94 explanation doesn\\x92t work any better. Some scientific work has no ',\n",
       " '89. The same is true of scientists generally. With possible rare exceptions, their motive is neither curiosity ',\n",
       " '90. Of course, it\\x92s not that simple. Other motives do play a role for many scientists. Money and status for ',\n",
       " '91. Also, science and technology constitute a power mass movement, and many scientists gratify their need ',\n",
       " '92. Thus science marches on blindly, without regard to the real welfare of the human race or to any other ',\n",
       " 'THE NATURE OF FREEDOMPARAG93. We are going to argue that industrial-technological society cannot be reformed in such a way as to ',\n",
       " '94. By \\x93freedom\\x94 we mean the opportunity to go through the power process, with real goals not the ',\n",
       " '95. It is said that we live in a free society because we have a certain number of constitutionally guaranteed ',\n",
       " '96. As for our constitutional rights, consider for example that of freedom of the press. We certainly don\\x92t ',\n",
       " '97. Constitutional rights are useful up to a point, but they do not serve to guarantee much more than what ',\n",
       " '98. One more point to be made in this section: It should not be assumed that a person has enough freedom ',\n",
       " 'SOME PRINCIPLES OF HISTORYPARAG99. Think of history as being the sum of two components: an erratic component that consists of ',\n",
       " '100. FIRST PRINCIPLE. If a SMALL change is made that affects a long-term historical trend, then the ',\n",
       " '101. The first principle is almost a tautology. If a trend were not stable with respect to small changes, it ',\n",
       " '102. SECOND PRINCIPLE. If a change is made that is sufficiently large to alter permanently a long-term ',\n",
       " '103. THIRD PRINCIPLE. If a change is made that is large enough to alter permanently a long-term trend, ',\n",
       " '104. FOURTH PRINCIPLE. A new kind of society cannot be designed on paper. That is, you cannot plan ',\n",
       " '105. The third and fourth principles result from the complexity of human societies. A change in human ',\n",
       " '106. FIFTH PRINCIPLE. People do not consciously and rationally choose the form of their society. ',\n",
       " '107. The fifth principle is a consequence of the other four.PARAG108. To illustrate: By the first principle, generally speaking an attempt at social reform either acts in the ',\n",
       " '109. The American Revolution does not provide a counterexample. The American \\x93Revolution\\x94 was not a ',\n",
       " '110. Still, one has to use common sense in applying the principles. They are expressed in imprecise ',\n",
       " 'PARAG111. The foregoing principles help to show how hopelessly difficult it would be to reform the industrial ',\n",
       " '112. People anxious to rescue freedom without sacrificing the supposed benefits of technology will suggest ',\n",
       " '113. So even on very general grounds it seems highly improbable that any way of changing society could be ',\n",
       " 'RESTRICTION OF FREEDOM IS UNAVOIDABLE IN INDUSTRIAL SOCIETYPARAG114. As explained in paragraphs 65-67, 70-73, modern man is strapped down by a network of rules and ',\n",
       " '115. The system HAS TO force people to behave in ways that are increasingly remote from the natural ',\n",
       " 'just the sort of thing that boys like. But in our society children are pushed into studying technical subjects, ',\n",
       " '116. Because of the constant pressure that the system exerts to modify human behavior, there is a gradual ',\n",
       " '117. In any technologically advanced society the individual\\x92s fate MUST depend on decisions that he ',\n",
       " '118. Conservatives and some others advocate more \\x93local autonomy.\\x94 Local communities once did have ',\n",
       " '119. The system does not and cannot exist to satisfy human needs. Instead, it is human behavior that has to ',\n",
       " '120. Efforts to make room for a sense of purpose and for autonomy within the system are no better than a ',\n",
       " 'THE \\x91BAD\\x92 PARTS OF TECHNOLOGY CANNOT BE SEPARATED FROM THE \\x91GOOD\\x92 PARTSPARAG121. A further reason why industrial society cannot be reformed in favor of freedom is that modern ',\n",
       " '122. Even if medical progress could be maintained without the rest of the technological system, it would by ',\n",
       " '123. If you think that big government interferes in your life too much NOW, just wait till the government ',\n",
       " '124. The usual response to such concerns is to talk about \\x93medical ethics.\\x94 But a code of ethics would not ',\n",
       " 'TECHNOLOGY IS A MORE POWERFUL SOCIAL FORCE THAN THE ASPIRATION FOR ',\n",
       " '125. It is not possible to make a LASTING compromise between technology and freedom, because ',\n",
       " '126. Let us explain why technology is a more powerful social force than the aspiration for freedom.PARAG127. A technological advance that appears not to threaten freedom often turns out to threaten it very ',\n",
       " '128. While technological progress AS A WHOLE continually narrows our sphere of freedom, each new ',\n",
       " '129. Another reason why technology is such a powerful social force is that, within the context of a given ',\n",
       " '130. Technology advances with great rapidity and threatens freedom at many different points at the same ',\n",
       " '131. Technicians (we use this term in its broad sense to describe all those who perform a specialized task ',\n",
       " '132. It is well known that people generally work better and more persistently when striving for a reward ',\n",
       " '133. No social arrangements, whether laws, institutions, customs or ethical codes, can provide permanent ',\n",
       " '134. For all of the foregoing reasons, technology is a more powerful social force than the aspiration for ',\n",
       " '135. In paragraph 125 we used an analogy of a weak neighbor who is left destitute by a strong neighbor ',\n",
       " 'SIMPLER SOCIAL PROBLEMS HAVE PROVED INTRACTABLEPARAG136. If anyone still imagines that it would be possible to reform the system in such a way as to protect ',\n",
       " '137. Take our environmental problems, for example. Here the conflict of values is straightforward: ',\n",
       " '138. Thus it is clear that the human race has at best a very limited capacity for solving even relatively ',\n",
       " '139. And note this important difference: It is conceivable that our environmental problems (for example) ',\n",
       " 'REVOLUTION IS EASIER THAN REFORMPARAG140. We hope we have convinced the reader that the system cannot be reformed in such a way as to ',\n",
       " '141. People tend to assume that because a revolution involves a much greater change than reform does, it is ',\n",
       " '142. Reform is always restrained by the fear of painful consequences if changes go too far. But once a ',\n",
       " 'CONTROL OF HUMAN BEHAVIORPARAG143. Since the beginning of civilization, organized societies have had to put pressures on human beings of ',\n",
       " '144. Thus human nature has in the past put certain limits on the development of societies. People could be ',\n",
       " '145. Imagine a society that subjects people to conditions that make them terribly unhappy, then gives them ',\n",
       " '146. Drugs that affect the mind are only one example of the new methods of controlling human behavior ',\n",
       " '147. To start with, there are the techniques of surveillance. Hidden video cameras are now used in most ',\n",
       " '148. Other techniques strike deeper than the foregoing. Education is no longer a simple affair of paddling a ',\n",
       " '149. Presumably, research will continue to increase the effectiveness of psychological techniques for ',\n",
       " '150. As we mentioned in paragraph 134, industrial society seems likely to be entering a period of severe ',\n",
       " '151. The social disruption that we see today is certainly not the result of mere chance. It can only be a result ',\n",
       " '152. Generally speaking, technological control over human behavior will probably not be introduced with a ',\n",
       " '153. Thus control over human behavior will be introduced not by a calculated decision of the authorities but ',\n",
       " '154. Suppose a biological trait is discovered that increases the likelihood that a child will grow up to be a ',\n",
       " '155. Our society tends to regard as a \\x93sickness\\x94 any mode of thought or behavior that is inconvenient for ',\n",
       " '156. In paragraph 127 we pointed out that if the use of a new item of technology is INITIALLY optional, it ',\n",
       " '157. Assuming that industrial society survives, it is likely that technology will eventually acquire something ',\n",
       " '158. It presumably would be impractical for all people to have electrodes inserted in their heads so that they ',\n",
       " '159. Will public resistance prevent the introduction of technological control of human behavior? It certainly ',\n",
       " '160. To those who think that all this sounds like science fiction, we point out that yesterday\\x92s science fiction ',\n",
       " 'HUMAN RACE AT A CROSSROADSPARAG161. But we have gotten ahead of our story. It is one thing to develop in the laboratory a series of ',\n",
       " '162. The system is currently engaged in a desperate struggle to overcome certain problems that threaten its ',\n",
       " '163. Suppose the system survives the crisis of the next several decades. By that time it will have to have ',\n",
       " '164. Don\\x92t imagine that the systems will stop developing further techniques for controlling human beings ',\n",
       " '165. But suppose on the other hand that the stresses of the coming decades prove to be too much for the ',\n",
       " '166. Therefore two tasks confront those who hate the servitude to which the industrial system is reducing ',\n",
       " 'PARAG167. The industrial system will not break down purely as a result of revolutionary action. It will not be ',\n",
       " '168. In the second place, one has to balance struggle and death against the loss of freedom and dignity. To ',\n",
       " '169. In the third place, it is not at all certain that survival of the system will lead to less suffering than ',\n",
       " '170. \\x93Oh!\\x94 say the technophiles, \\x93Science is going to fix all that! We will conquer famine, eliminate ',\n",
       " 'THE FUTUREPARAG171. But suppose now that industrial society does survive the next several decades and that the bugs do ',\n",
       " '172. First let us postulate that the computer scientists succeed in developing intelligent machines that can do ',\n",
       " '173. If the machines are permitted to make all their own decisions, we can\\x92t make any conjectures as to the ',\n",
       " '174. On the other hand it is possible that human control over the machines may be retained. In that case the ',\n",
       " '175. But suppose now that the computer scientists do not succeed in developing artificial intelligence, so ',\n",
       " '176. One can envision scenarios that incorporate aspects of more than one of the possibilities that we have ',\n",
       " '177. Needless to say, the scenarios outlined above do not exhaust all the possibilities. They only indicate ',\n",
       " '178. Whatever else may be the case, it is certain that technology is creating for human beings a new ',\n",
       " '179. It would be better to dump the whole stinking system and take the consequences.PARAGSTRATEGYPARAG180. The technophiles are taking us all on an utterly reckless ride into the unknown. Many people ',\n",
       " '181. As we stated in paragraph 166, the two main tasks for the present are to promote social stress and ',\n",
       " '182. It will be objected that the French and Russian Revolutions were failures. But most revolutions have ',\n",
       " '183. But an ideology, in order to gain enthusiastic support, must have a positive ideal as well as a negative ',\n",
       " '184. Nature makes a perfect counter-ideal to technology for several reasons. Nature (that which is outside ',\n",
       " '185. As for the negative consequences of eliminating industrial society\\x97well, you can\\x92t eat your cake and ',\n",
       " '186. Most people hate psychological conflict. For this reason they avoid doing any serious thinking about ',\n",
       " '187. On the more sophisticated level the ideology should address itself to people who are intelligent, ',\n",
       " '188. On a second level, the ideology should be propagated in a simplified form that will enable the ',\n",
       " '189. Prior to that final struggle, the revolutionaries should not expect to have a majority of people on their ',\n",
       " '190. Any kind of social conflict helps to destabilize the system, but one should be careful about what kind ',\n",
       " '191. One should think twice before encouraging any other social conflict than that between the power-',\n",
       " '192. But the way to discourage ethnic conflict is NOT through militant advocacy of minority rights (see ',\n",
       " '193. The kind of revolution we have in mind will not necessarily involve an armed uprising against any ',\n",
       " '194. Probably the revolutionaries should even AVOID assuming political power, whether by legal or illegal ',\n",
       " '195. The revolution must be international and worldwide. It cannot be carried out on a nation-by-nation ',\n",
       " '196. Revolutionaries might consider favoring measures that tend to bind the world economy into a unified ',\n",
       " '197. Some people take the line that modern man has too much power, too much control over nature; they ',\n",
       " '198. Primitive INDIVIDUALS and SMALL GROUPS actually had considerable power over nature; or ',\n",
       " '199. Instead of arguing for powerlessness and passivity, one should argue that the power of the ',\n",
       " '200. Until the industrial system has been thoroughly wrecked, the destruction of that system must be the ',\n",
       " '201. Suppose for example that the revolutionaries took \\x93social justice\\x94 as a goal. Human nature being what ',\n",
       " '202. It would be hopeless for revolutionaries to try to attack the system without using SOME modern ',\n",
       " '203. Imagine an alcoholic sitting with a barrel of wine in front of him. Suppose he starts saying to himself, ',\n",
       " '204. Revolutionaries should have as many children as they can. There is strong scientific evidence that ',\n",
       " '205. The trouble is that many of the people who are inclined to rebel against the industrial system are also ',\n",
       " '206. With regard to revolutionary strategy, the only points on which we absolutely insist are that the single ',\n",
       " 'TWO KINDS OF TECHNOLOGYPARAG207. An argument likely to be raised against our proposed revolution is that it is bound to fail, because (it is ',\n",
       " '208. We distinguish between two kinds of technology, which we will call small-scale technology and ',\n",
       " '209. The reason why technology has seemed always to progress is that, until perhaps a century or two ',\n",
       " '210. So it is clear that if the industrial system were once thoroughly broken down, refrigeration technology ',\n",
       " '211. In the late Middle Ages there were four main civilizations that were about equally \\x93advanced\\x94: Europe, ',\n",
       " '212. Would society EVENTUALLY develop again toward an industrial-technological form? Maybe, but ',\n",
       " 'THE DANGER OF LEFTISMPARAG213. Because of their need for rebellion and for membership in a movement, leftists or persons of similar ',\n",
       " '214. To avoid this, a movement that exalts nature and opposes technology must take a resolutely anti-leftist ',\n",
       " '215. The anarchist [34] too seeks power, but he seeks it on an individual or small-group basis; he wants ',\n",
       " '216. Some leftists may seem to oppose technology, but they will oppose it only so long as they are outsiders ',\n",
       " '217. In earlier revolutions, leftists of the most power-hungry type, repeatedly, have first cooperated with ',\n",
       " '218. Various thinkers have pointed out that leftism is a kind of religion. Leftism is not a religion in the strict ',\n",
       " '219. Leftism is a totalitarian force. Wherever leftism is in a position of power it tends to invade every ',\n",
       " '220. Suppose you asked leftists to make a list of ALL the things that were wrong with society, and then ',\n",
       " '221. Because of the restrictions placed on their thoughts and behavior by their high level of socialization, ',\n",
       " '222. Leftists, especially those of the oversocialized type, are True Believers in the sense of Eric Hoffer\\x92s ',\n",
       " '223. Some readers may say, \\x93This stuff about leftism is a lot of crap. I know John and Jane who are leftish ',\n",
       " '224. The people who rise to positions of power in leftist movements tend to be leftists of the most power-',\n",
       " '225. These phenomena appeared clearly in Russia and other countries that were taken over by leftists. ',\n",
       " '226. Thus the fact that many individual leftists are personally mild and fairly tolerant people by no means ',\n",
       " '227. Our discussion of leftism has a serious weakness. It is still far from clear what we mean by the word ',\n",
       " '228. But it will be helpful to list some criteria for diagnosing leftism. These criteria cannot be applied in a ',\n",
       " '229. The leftist is oriented toward large-scale collectivism. He emphasizes the duty of the individual to ',\n",
       " '230. The more dangerous leftists, that is, those who are most power-hungry, are often characterized by ',\n",
       " 'PARAG231. Throughout this article we\\x92ve made imprecise statements and statements that ought to have had all ',\n",
       " '232. All the same, we are reasonably confident that the general outlines of the picture we have painted here ',\n",
       " 'NotesPARAG1. (Paragraph 19) We are asserting that ALL, or even most, bullies and ruthless competitors ',\n",
       " '2. (Paragraph 25) During the Victorian period many oversocialized people suffered from serious ',\n",
       " '3. (Paragraph 27) Not necessarily including specialists in engineering or the \\x93hard\\x94 sciences.PARAG4. (Paragraph 28) There are many individuals of the middle and upper classes who resist some of these ',\n",
       " 'The main reason why these values have become, so to speak, the official values of our society is that they ',\n",
       " '5. (Paragraph 42) It may be argued that the majority of people don\\x92t want to make their own decisions but ',\n",
       " '6. (Paragraph 44) Some of the symptoms listed are similar to those shown by caged animals.PARAGTo explain how these symptoms arise from deprivation with respect to the power process:PARAGCommon-sense understanding of human nature tells one that lack of goals whose attainment requires effort ',\n",
       " 'The foregoing is a simplification. Reality is more complex, and of course, deprivation with respect to the ',\n",
       " 'By the way, when we mention depression we do not necessarily mean depression that is severe enough to be ',\n",
       " '7. (Paragraph 52) A partial exception may be made for a few passive, inward-looking groups, such as the ',\n",
       " 'Or take the gypsies. The gypsies commonly get away with theft and fraud because their loyalties are such ',\n",
       " 'Some of the early-20th century Chinese thinkers who were concerned with modernizing China recognized ',\n",
       " '8. (Paragraph 56) Yes, we know that 19th century America had its problems, and serious ones, but for the ',\n",
       " '9. (Paragraph 61) We leave aside the \\x93underclass.\\x94 We are speaking of the mainstream.PARAG10. (Paragraph 62) Some social scientists, educators, \\x93mental health\\x94 professionals and the like are doing ',\n",
       " '11. (Paragraphs 63, 82) Is the drive for endless material acquisition really an artificial creation of the ',\n",
       " '12. (Paragraph 64) The problem of purposelessness seems to have become less serious during the last 15 ',\n",
       " '13. (Paragraph 66) Conservatives\\x92 efforts to decrease the amount of government regulation are of little ',\n",
       " '14. (Paragraph 73) When someone approves of the purpose for which propaganda is being used in a given ',\n",
       " '15. (Paragraph 83) We are not expressing approval or disapproval of the Panama invasion. We only use it ',\n",
       " '16. (Paragraph 95) When the American colonies were under British rule there were fewer and less effective ',\n",
       " '\\x93The progressive heightening of standards of propriety, and with it the increasing reliance on official law ',\n",
       " '\\x93The results of the new organization of life and work were apparent by 1900, when some 76 percent of the ',\n",
       " '17. (Paragraph 117) Apologists for the system are fond of citing cases in which elections have been decided ',\n",
       " '18. (Paragraph 119) \\x93Today, in technologically advanced lands, men live very similar lives in spite of ',\n",
       " 'The lives of the three bank clerks are not IDENTICAL. Ideology does have SOME effect. But all ',\n",
       " '19. (Paragraph 123) Just think an irresponsible genetic engineer might create a lot of terrorists.PARAG20. (Paragraph 124) For a further example of undesirable consequences of medical progress, suppose a ',\n",
       " '21. (Paragraph 128) Since many people may find paradoxical the notion that a large number of good things ',\n",
       " 'The situation of modern man is analogous to that of Mr. A. The system makes an individual\\x92s life easier for ',\n",
       " '22. (Paragraph 137) Here we are considering only the conflict of values within the mainstream. For the sake ',\n",
       " '23. (Paragraph 137) Self-interest is not necessarily MATERIAL self-interest. It can consist in fulfillment of ',\n",
       " '24. (Paragraph 139) A qualification: It is in the interest of the system to permit a certain prescribed degree ',\n",
       " '25. (Paragraph 143) We don\\x92t mean to suggest that the efficiency or the potential for survival of a society ',\n",
       " '26. (Paragraph 147) If you think that more effective law enforcement is unequivocally good because it ',\n",
       " 'If a society needs a large, powerful law enforcement establishment, then there is something gravely wrong ',\n",
       " '27. (Paragraph 151) To be sure, past societies have had means of influencing human behavior, but these ',\n",
       " '28. (Paragraph 152) However, some psychologists have publicly expressed opinions indicating their ',\n",
       " '29. (Paragraph 154) This is no science fiction! After writing paragraph 154 we came across an article in ',\n",
       " '30. (Paragraph 184) A further advantage of nature as a counter-ideal to technology is that, in many people, ',\n",
       " 'Thus there is a religious vacuum in our society that could perhaps be filled by a religion focused on nature ',\n",
       " 'It is probably best not to try to introduce religion into the conflict of nature vs. technology unless you ',\n",
       " '31. (Paragraph 189) Assuming that such a final push occurs. Conceivably the industrial system might be ',\n",
       " '32. (Paragraph 193) It is even conceivable (remotely) that the revolution might consist only of a massive ',\n",
       " '33. (Paragraph 195) The economic and technological structure of a society are far more important than its ',\n",
       " '34. (Paragraph 215) This statement refers to our particular brand of anarchism. A wide variety of social ',\n",
       " '35. (Paragraph 219) Many leftists are motivated also by hostility, but the hostility probably results in part ',\n",
       " '36. (Paragraph 229) It is important to understand that we mean someone who sympathizes with these ',\n",
       " 'If copyright problems make it impossible for this long quotation to be printed, then please change Note 16 ',\n",
       " '16. (Paragraph 95) When the American colonies were under British rule there were fewer and less effective ',\n",
       " 'PARAGPARAG&copy Copyright 1997 The Digital Ink CompanyPARAGUnabomber Special Report | ',\n",
       " 'Back to the topPARAG',\n",
       " '']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "parags = re.findall('(?<=PARAG).*',tedText)\n",
    "parags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty close to what I wanted. Note that most of these are paragraphs with the author's original numbering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parags[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why does it just stop right there? From the documentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `.` matches any character except a newline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That explains it. So what if we wanted just the first word following a \"PARAG\"? We could do, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Editor's\",\n",
       " 'Return',\n",
       " 'PARAGPARAGIntroductionPARAG1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " 'THE',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " 'FEELINGS',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " 'OVERSOCIALIZATIONPARAG24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.',\n",
       " '31.',\n",
       " '32.',\n",
       " 'THE',\n",
       " '33.',\n",
       " '34.',\n",
       " '35.',\n",
       " '36.',\n",
       " '37,',\n",
       " 'SURROGATE',\n",
       " '38.',\n",
       " '39.',\n",
       " '40.',\n",
       " '41.',\n",
       " 'AUTONOMYPARAG42.',\n",
       " '43.',\n",
       " '44.',\n",
       " 'SOURCES',\n",
       " '45.',\n",
       " '46.',\n",
       " '47.',\n",
       " '48.',\n",
       " '49.',\n",
       " '50.',\n",
       " '51.',\n",
       " '52.',\n",
       " '53.',\n",
       " '54.',\n",
       " '55.',\n",
       " '56.',\n",
       " '57.',\n",
       " '58.',\n",
       " 'DISRUPTION',\n",
       " '59.',\n",
       " '60.',\n",
       " '61.',\n",
       " '62.',\n",
       " '63.',\n",
       " '64.',\n",
       " '65.',\n",
       " '66.',\n",
       " '67.',\n",
       " '68.',\n",
       " '69.',\n",
       " '70.',\n",
       " '71.',\n",
       " '72.',\n",
       " '73.',\n",
       " '74.',\n",
       " '75.',\n",
       " '76.',\n",
       " 'HOW',\n",
       " '77.',\n",
       " '78.',\n",
       " '79.',\n",
       " '80.',\n",
       " '81.',\n",
       " '82.',\n",
       " '83.',\n",
       " '84.',\n",
       " '85.',\n",
       " '86.',\n",
       " 'THE',\n",
       " '87.',\n",
       " '88.',\n",
       " '89.',\n",
       " '90.',\n",
       " '91.',\n",
       " '92.',\n",
       " 'THE',\n",
       " '93.',\n",
       " '94.',\n",
       " '95.',\n",
       " '96.',\n",
       " '97.',\n",
       " '98.',\n",
       " 'SOME',\n",
       " '99.',\n",
       " '100.',\n",
       " '101.',\n",
       " '102.',\n",
       " '103.',\n",
       " '104.',\n",
       " '105.',\n",
       " '106.',\n",
       " '107.',\n",
       " '108.',\n",
       " '109.',\n",
       " '110.',\n",
       " 'PARAG111.',\n",
       " '112.',\n",
       " '113.',\n",
       " 'RESTRICTION',\n",
       " '114.',\n",
       " '115.',\n",
       " 'just',\n",
       " '116.',\n",
       " '117.',\n",
       " '118.',\n",
       " '119.',\n",
       " '120.',\n",
       " 'THE',\n",
       " '121.',\n",
       " '122.',\n",
       " '123.',\n",
       " '124.',\n",
       " 'TECHNOLOGY',\n",
       " '125.',\n",
       " '126.',\n",
       " '127.',\n",
       " '128.',\n",
       " '129.',\n",
       " '130.',\n",
       " '131.',\n",
       " '132.',\n",
       " '133.',\n",
       " '134.',\n",
       " '135.',\n",
       " 'SIMPLER',\n",
       " '136.',\n",
       " '137.',\n",
       " '138.',\n",
       " '139.',\n",
       " 'REVOLUTION',\n",
       " '140.',\n",
       " '141.',\n",
       " '142.',\n",
       " 'CONTROL',\n",
       " '143.',\n",
       " '144.',\n",
       " '145.',\n",
       " '146.',\n",
       " '147.',\n",
       " '148.',\n",
       " '149.',\n",
       " '150.',\n",
       " '151.',\n",
       " '152.',\n",
       " '153.',\n",
       " '154.',\n",
       " '155.',\n",
       " '156.',\n",
       " '157.',\n",
       " '158.',\n",
       " '159.',\n",
       " '160.',\n",
       " 'HUMAN',\n",
       " '161.',\n",
       " '162.',\n",
       " '163.',\n",
       " '164.',\n",
       " '165.',\n",
       " '166.',\n",
       " 'PARAG167.',\n",
       " '168.',\n",
       " '169.',\n",
       " '170.',\n",
       " 'THE',\n",
       " '171.',\n",
       " '172.',\n",
       " '173.',\n",
       " '174.',\n",
       " '175.',\n",
       " '176.',\n",
       " '177.',\n",
       " '178.',\n",
       " '179.',\n",
       " 'STRATEGYPARAG180.',\n",
       " '181.',\n",
       " '182.',\n",
       " '183.',\n",
       " '184.',\n",
       " '185.',\n",
       " '186.',\n",
       " '187.',\n",
       " '188.',\n",
       " '189.',\n",
       " '190.',\n",
       " '191.',\n",
       " '192.',\n",
       " '193.',\n",
       " '194.',\n",
       " '195.',\n",
       " '196.',\n",
       " '197.',\n",
       " '198.',\n",
       " '199.',\n",
       " '200.',\n",
       " '201.',\n",
       " '202.',\n",
       " '203.',\n",
       " '204.',\n",
       " '205.',\n",
       " '206.',\n",
       " 'TWO',\n",
       " '207.',\n",
       " '208.',\n",
       " '209.',\n",
       " '210.',\n",
       " '211.',\n",
       " '212.',\n",
       " 'THE',\n",
       " '213.',\n",
       " '214.',\n",
       " '215.',\n",
       " '216.',\n",
       " '217.',\n",
       " '218.',\n",
       " '219.',\n",
       " '220.',\n",
       " '221.',\n",
       " '222.',\n",
       " '223.',\n",
       " '224.',\n",
       " '225.',\n",
       " '226.',\n",
       " '227.',\n",
       " '228.',\n",
       " '229.',\n",
       " '230.',\n",
       " 'PARAG231.',\n",
       " '232.',\n",
       " 'NotesPARAG1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " 'The',\n",
       " '5.',\n",
       " '6.',\n",
       " 'To',\n",
       " 'Common-sense',\n",
       " 'The',\n",
       " 'By',\n",
       " '7.',\n",
       " 'Or',\n",
       " 'Some',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '\\x93The',\n",
       " '\\x93The',\n",
       " '17.',\n",
       " '18.',\n",
       " 'The',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " 'The',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " 'If',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.',\n",
       " '30.',\n",
       " 'Thus',\n",
       " 'It',\n",
       " '31.',\n",
       " '32.',\n",
       " '33.',\n",
       " '34.',\n",
       " '35.',\n",
       " '36.',\n",
       " 'If',\n",
       " '16.',\n",
       " 'PARAGPARAG&copy',\n",
       " 'Unabomber',\n",
       " 'Back',\n",
       " '']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "parags = re.findall('(?<=PARAG)\\S*',tedText)\n",
    "parags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad. What about the next couple of words? (**exercise**). There is (almost) no limit to what you can express with REs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrapy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a tool for automating web scraping.\n",
    ">Scrapy is an application framework for crawling web sites and extracting structured data which can be used for a wide range of useful applications, like data mining, information processing or historical archival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's step through the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a new terminal in Jupyter (or otherwise open a new terminal)\n",
    "2. Enter `scrapy startproject tutorial` (or another name for your tutorial project)\n",
    "3. Copy or type the below code into a text file that we'll call `quotes_spider.py`. Create that file in `tutorial/tutorial/spiders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class definition for your first scrapy spider\n",
    "import scrapy\n",
    "\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [\n",
    "            'http://quotes.toscrape.com/page/1/',\n",
    "            'http://quotes.toscrape.com/page/2/',\n",
    "        ]\n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        page = response.url.split(\"/\")[-2]\n",
    "        filename = 'quotes-%s.html' % page\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.body)\n",
    "        self.log('Saved file %s' % filename) # old-fashioned string parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks on these definitions:\n",
    "* `name` identifies the Spider. It must be unique within a project, that is, you can’t set the same name for different Spiders.\n",
    "\n",
    "* `start_requests()` must return an iterable of Requests (you can return a list of requests or write a generator function) which the Spider will begin to crawl from. Subsequent requests will be generated successively from these initial requests.\n",
    "\n",
    "* `parse()` a method that will be called to handle the response downloaded for each of the requests made. The response parameter is an instance of TextResponse that holds the page content and has further helpful methods to handle it.\n",
    "The `parse()` method usually parses the response, extracting the scraped data as dicts and also finding new URLs to follow and creating new requests (`Request`) from them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Go to the top-level directory (`tutorial`) and run `scrapy crawl quotes`.\n",
    "5. Look around (`ls`) the directory. Examine the new files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you'll notice about this example is that we really didn't do any parsing. Let's fix that by updating our spider. Replace the parse method definition in `quotes_spider.py` with the new one below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(*Remark* you can use the scrapy shell to play with the methods used below: `scrapy shell \"some_url.com\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self, response):\n",
    "    for quote in response.css('div.quote'):\n",
    "        yield {\n",
    "            'text': quote.css('span.text::text').extract_first(),\n",
    "            'author': quote.css('small.author::text').extract_first(),\n",
    "            'tags': quote.css('div.tags a.tag::text').extract(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the command `scrapy crawl quotes -o quotes.json` to extract data from these pages and store the parsed results in the file `quotes.json`.\n",
    "\n",
    "Then take a look (e.g. `cat quotes.json`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are sort of scraping, but there is no *crawling* to speak of. What does that mean, crawling? Let's see how to follow links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the contents of `quotes_spider.py` with the code below. Note that this one also uses the `start_urls` shortcut (which you can read about on the tutorial page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').extract_first(),\n",
    "                'author': quote.css('small.author::text').extract_first(),\n",
    "                'tags': quote.css('div.tags a.tag::text').extract(),\n",
    "            }\n",
    "\n",
    "        next_page = response.css('li.next a::attr(href)').extract_first()\n",
    "        if next_page is not None:\n",
    "            next_page = response.urljoin(next_page)\n",
    "            yield scrapy.Request(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what has changed: we have extracted links and included logic to move to the next one in the list. More precisely...\n",
    ">Now, after extracting the data, the `parse()` method looks for the link to the next page, builds a full absolute URL using the `urljoin()` method (since the links can be relative) and yields a new request to the next page, registering itself as callback to handle the data extraction for the next page and to keep the crawling going through all the pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What else can you do? Here is one example of a slightly more advanced spider that scrapes author information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "\n",
    "class AuthorSpider(scrapy.Spider):\n",
    "    name = 'author'\n",
    "\n",
    "    start_urls = ['http://quotes.toscrape.com/']\n",
    "\n",
    "    def parse(self, response):\n",
    "        # follow links to author pages\n",
    "        for href in response.css('.author + a::attr(href)'):\n",
    "            yield response.follow(href, self.parse_author)\n",
    "\n",
    "        # follow pagination links\n",
    "        for href in response.css('li.next a::attr(href)'):\n",
    "            yield response.follow(href, self.parse)\n",
    "\n",
    "    def parse_author(self, response):\n",
    "        def extract_with_css(query):\n",
    "            return response.css(query).extract_first().strip()\n",
    "\n",
    "        yield {\n",
    "            'name': extract_with_css('h3.author-title::text'),\n",
    "            'birthdate': extract_with_css('.author-born-date::text'),\n",
    "            'bio': extract_with_css('.author-description::text'),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the tutorial:\n",
    ">This spider will start from the main page, it will follow all the links to the authors pages calling the `parse_author` callback for each of them, and also the pagination links with the `parse` callback as we saw before."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
