{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS600 - Python Programming for Finance \n",
    "###  \n",
    "<img src=\"https://www.syracuse.edu/wp-content/themes/g6-carbon/img/syracuse-university-seal.svg?ver=6.3.9\" style=\"width: 200px;\"/>\n",
    "\n",
    "## Financial Time Series\n",
    "\n",
    "###  October 25, 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First Steps with the `DataFrame`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas DataFrame class is designed to manage indexed and labeled data \n",
    "# Data itself can be provided in different shapes and types \n",
    "#    (list, tuple, ndarray, and dict objects).\n",
    "# Create DataFrame object\n",
    "\n",
    "df = pd.DataFrame([10, 20, 30, 40], columns=['numbers'],\n",
    "                  index=['a', 'b', 'c', 'd'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is an index that can take on different formats \n",
    "# (e.g., numbers, strings, time information).\n",
    "\n",
    "df.index  # the index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is organized in columns, which can have custom names\n",
    "\n",
    "df.columns  # the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix['c']  # selection via index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix[['a', 'd']]  # selection of multiple indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ix[df.index[1:3]]  # selection via Index object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()  # sum per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda x: x ** 2)  # square of every element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df ** 2  # again square, this time NumPy-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['floats'] = (1.5, 2.5, 3.5, 4.5)\n",
    "  # new column is generated\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['floats']  # selection of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['names'] = pd.DataFrame(['Yves', 'Guido', 'Peter', 'Travis'],\n",
    "                           index=['d', 'a', 'b', 'c'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.append({'numbers': 100, 'floats': 5.75, 'names': 'Henry'},\n",
    "               ignore_index=True)\n",
    "    # temporary object; df not changed\n",
    "    # the index gets replaced by a simple numbered index\n",
    "    # avoid ignoring index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is  better to append a DataFrame object, \n",
    "# providing the appropriate index information\n",
    "\n",
    "df = df.append(pd.DataFrame({'numbers': 100, 'floats': 5.75,\n",
    "                             'names': 'Henry'}, index=['z',]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code  adds a new column, but with a slightly different index.\n",
    "# Pandas by default accepts only values for those indices that already exist. \n",
    "# We lose the value for the index y and have a NaN value \n",
    "# (i.e., “Not a Number”) at index position z.\n",
    "\n",
    "df.join(pd.DataFrame([1, 4, 9, 16, 25],\n",
    "            index=['a', 'b', 'c', 'd', 'y'],\n",
    "            columns=['squares',]))\n",
    "  # temporary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use how=“outer” to use the union of all values from both indices\n",
    "\n",
    "df = df.join(pd.DataFrame([1, 4, 9, 16, 25],\n",
    "                    index=['a', 'b', 'c', 'd', 'y'],\n",
    "                    columns=['squares',]),\n",
    "                    how='outer')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['numbers', 'squares']].mean()\n",
    "  # column-wise mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['numbers', 'squares']].std()\n",
    "  # column-wise standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Steps with DataFrame Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a numpy.ndarry with, with  nine rows and four columns \n",
    "# of  pseudorandom, standard normally distributed numbers\n",
    "\n",
    "a = np.random.standard_normal((9, 4))\n",
    "a.round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(a)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Parameters of DataFrame function\n",
    "# Parameter Format                   Description\n",
    "# --------- ------                   -----------\n",
    "# data      ndarray/dict/DataFrame   Data for DataFrame; dict can contain Series, ndarrays, lists\n",
    "# index     Index/array-like         Index to use; defaults to range(n)\n",
    "# columns   Index/array-like         Column headers to use; defaults to range(n)\n",
    "# dtype     dtype, default None      Data type to use/force; otherwise, it is inferred\n",
    "# copy      bool, default None       Copy data from inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [['No1', 'No2', 'No3', 'No4']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['No2'][3]  # value in column No2 at index position 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume that our nine data entries in the four columns correspond to\n",
    "# month-end data, beginning in January 2015.\n",
    "\n",
    "# freq = 'M'     Month end frequency  (See Table 6.3)\n",
    "# periods = 9    number of periods \n",
    "\n",
    "dates = pd.date_range('2015-1-1', periods=9, freq='M')\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we assign the newly generated DatetimeIndex \n",
    "# as the new Index object to the DataFrame object\n",
    "\n",
    "df.index = dates\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can generate a DataFrame object in general from an ndarray object. \n",
    "# You can also generate an ndarray object out of a DataFrame by using the function array of NumPy.\n",
    "\n",
    "np.array(df).round(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sum()   # column-wise sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean()   # column-wise means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.cumsum()  #column-wise cumulative sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()   # a number of often-used statistics for numerical data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can  apply the majority of NumPy universal functions to DataFrame objects\n",
    "\n",
    "np.sqrt(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas leaves out the NaN values and only works with the other available values\n",
    "\n",
    "np.sqrt(df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting of data\n",
    "# pandas provides a wrapper around matplotplib, specifically designed for DataFrame objects\n",
    "\n",
    "# Parameters of plot method are listed in table 6.4\n",
    "#  subplots  Boolean, default False    Plot columns in subplots\n",
    "#  grid      Boolean, default False    Horizontal and vertical grid lines\n",
    "#  title     String, default None      Title for the plot\n",
    "#  legend    Boolean, default True     Legend of labels\n",
    "#  logx      Boolean, default False    Logarithmic scaling of x-axis\n",
    "#  logy      Boolean, default False    Logarithmic scaling of y-axis\n",
    "#  xlim      2-tuple, list             Boundaries for x-axis\n",
    "#  ylim      2-tuple, list             Boundaries for y-axis\n",
    "#    etc...\n",
    "\n",
    "%matplotlib inline\n",
    "df.cumsum().plot(lw=2.0, # subplots = True\n",
    "                 grid = True)\n",
    "# title: Line plot of a DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeSeries Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have worked mainly with the pandas DataFrame class\n",
    "\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is  a dedicated Series class. We get a Series object, \n",
    "# for example, when selecting a single column from our DataFrame object\n",
    "\n",
    "df['No1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['No1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot Series objets\n",
    "# style = 'b'     blue line   \n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df['No1'].cumsum().plot(style='b', lw=2.)\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('value')\n",
    "plt.grid()\n",
    "plt.title(\"Line plot of a TimeSeries object\")\n",
    "# title: Line plot of a TimeSeries object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GroupBy Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas has powerful and flexible grouping capabilities\n",
    "# similar to grouping in SQL as well as pivot tables in Microsoft Excel\n",
    "\n",
    "# To have something to group by, we add a column \n",
    "# indicating the quarter the respective data\n",
    "\n",
    "df['Quarter'] = ['Q1', 'Q1', 'Q1', 'Q2', 'Q2', 'Q2', 'Q3', 'Q3', 'Q3']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can group by the “Quarter” column\n",
    "\n",
    "groups = df.groupby('Quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping can also be done with multiple columns. \n",
    "# add another column, indicating whether the month of the index date is odd or even\n",
    "\n",
    "df['Odd_Even'] = ['Odd', 'Even', 'Odd', 'Even', 'Odd', 'Even',\n",
    "                  'Odd', 'Even', 'Odd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping based on two columns simultaneously\n",
    "\n",
    "groups = df.groupby(['Quarter', 'Odd_Even'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Financial Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `iexfinance` as before. And we will download some other data from the web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "uuid": "9805e014-8a17-4e54-b6fd-1c77db7b6b78"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from iexfinance import get_historical_data\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are downloading *Apple* stock data (historical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2014, 2, 9)\n",
    "#end = datetime(2017, 5, 24)\n",
    "\n",
    "AAPL = get_historical_data(\"AAPL\", start=start,  output_format='pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily visualize..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL['close'].plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of the vectorization provided by `pandas` in computing a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL['return'] = np.log(AAPL['close'] / AAPL['close'].shift(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL.close.shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot these two next two each other with a single line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL[['close','return']].plot(subplots=True,style='b',figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is allegedly demonstrating some principles in finance (i.e. *volatility clustering* and *leveraging effect*), but I've substituted different data for the textbook's, so you tell me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most basic moves one makes in analyzing time series data is to calculate a *rolling average* or *rolling mean*. There's a method for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL['42d'] = AAPL.close.rolling(window=42).mean()\n",
    "AAPL['252d'] = AAPL.close.rolling(window=252).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can plot the two of these together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL[['close','42d','252d']].plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another financial metric a trader might want to calculate is the *moving volatility*, which is given by the rolling *standard deviation* of the return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL['movVol'] = AAPL['return'].rolling(window=252).std()*np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL[['close','movVol','return']].plot(subplots=True,style='b',figsize=(8,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to do a better job of illustrating those two principles mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about quantifying and automatically detecting the patterns we find in plots like the ones we made above. This is *regression analysis* and is basically glorified curve-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to get our hands on some nice new data from [Stoxx](stoxx.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports (the latter for later)\n",
    "from urllib.request import urlretrieve\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Here downloading the data\n",
    "es_url = 'http://www.stoxx.com/download/historical_values/hbrbcpe.txt'\n",
    "vs_url = 'http://www.stoxx.com/download/historical_values/h_vstoxx.txt'\n",
    "urlretrieve(es_url, 'es.txt')\n",
    "urlretrieve(vs_url, 'vs.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(might take a moment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have this data...what is it?\n",
    "\n",
    "* EURO STOXX 50 index\n",
    "    >  Historical\tdaily\tclosing\tvalues\tof\tthe\tEURO\tSTOXX\t50\tindex,\tcomposed\tof European\tblue-chip\tstocks\n",
    "* VSTOXX\n",
    "    > Historical daily closing\tdata for the VSTOXX volatility index, calculated\ton\tthe\tbasis of volatilities implied by options on\tthe\tEURO STOXX 50 index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first of these, call it `es`, needs some formatting changes. You can reverse engineer the following cell if you feel like it; I think it is really not interesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date;SX5P;SX5E;SXXP;SXXE;SXXF;SXXA;DK5F;DKXF;DEL\\n',\n",
       " '31.12.1986;775.00;900.82;82.76;98.58;98.06;69.06;645.26;65.56\\n',\n",
       " '01.01.1987;775.00;900.82;82.76;98.58;98.06;69.06;645.26;65.56\\n',\n",
       " '02.01.1987;770.89;891.78;82.57;97.80;97.43;69.37;647.62;65.81\\n',\n",
       " '05.01.1987;771.89;898.33;82.82;98.60;98.19;69.16;649.94;65.82\\n']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('es.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "lines = [line.replace(' ', '') for line in lines]\n",
    "\n",
    "with open('es50.txt', 'w') as new_file:\n",
    "    new_file.writelines('date' + lines[3][:-1]\n",
    "                        + ';DEL' + lines[3][-1])\n",
    "        # writes the corrected third line of the orginal file\n",
    "        # as first line of new file\n",
    "    new_file.writelines(lines[4:])\n",
    "        # writes the remaining lines of the orginial file\n",
    "\n",
    "new_lines = open('es50.txt', 'r').readlines()\n",
    "new_lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is ready to be read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = pd.read_csv('es50.txt',index_col=0,parse_dates=True,sep=';',dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(es.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See that little guy on the end? We don't need that little guy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "del es['DEL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want the VSTOXX set. That one is already nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = pd.read_csv('vs.txt',index_col=0,parse_dates=True,header=2,sep=',',dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt # Needed for next thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just one column, filtered, from the first\n",
    "data = pd.DataFrame({'EUROSTOXX' :\n",
    "                     es['SX5E'][es.index > dt.datetime(1999, 1, 1)]})\n",
    "\n",
    "# Combining with another column, also filtered, from the second\n",
    "data = data.join(pd.DataFrame({'VSTOXX' :\n",
    "                     vs['V2TX'][vs.index > dt.datetime(1999, 1, 1)]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  fill missing values with the last available values from the time series. \n",
    "\n",
    "We call the fillna method, providing ffill (for forward fill) as the method parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good! How about a look at the plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(subplots=True, grid=True, style='b', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also quickly look at the log returns of the two quantities in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating - massive broadcasting here\n",
    "rets = np.log(data / data.shift(1)) \n",
    "rets.dropna(inplace=True)\n",
    "\n",
    "rets.plot(subplots=True, grid=True, style='b', figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to hit it with the linear regression hammer. We take the `es` values as the *independent* or *predictor* variable, and the `vs` variables as the *dependent* or *response* variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is unfortunately some nasty stuff in there, so lets get rid of it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "rets.dropna(inplace=True)\n",
    "rets = rets[(rets.EUROSTOXX != np.inf) & (rets.EUROSTOXX != -np.inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdat = rets['EUROSTOXX']\n",
    "ydat = rets['VSTOXX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is now very easy to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(ydat, xdat)\n",
    "olsres = model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the line of predicted values for this sucker together with a scatterplot of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = olsres.predict(xdat) # Getting the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "p = figure(plot_width=400, plot_height=400)\n",
    "\n",
    "p.circle(xdat, ydat, size=20, color=\"navy\", alpha=0.5)\n",
    "\n",
    "p.line(xdat,preds,color='firebrick')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
