{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS600 - Python Programming for Finance \n",
    "###  \n",
    "<img src=\"https://www.syracuse.edu/wp-content/themes/g6-carbon/img/syracuse-university-seal.svg?ver=6.3.9\" style=\"width: 200px;\"/>\n",
    "\n",
    "# Python IO\n",
    "\n",
    "###  September 11, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From last time..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File IO & Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we're going to see some basic IO operations and learn how to process text by following an example from *Think Python, $2^{nd}$ Edition*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Example - Processing Text from a Book*\n",
    ">Write a program that reads a file, breaks each line into words, strips whitespace and punctuation from the words and converts them to lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is one quick way to download a text from inside our Python session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Emma.txt', <http.client.HTTPMessage at 0x7fbc7aa36358>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "request.urlretrieve (\"https://www.gutenberg.org/files/158/158-0.txt\", \"Emma.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While we're at it, let's download the `words.txt` from *Think Python*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('words.txt', <http.client.HTTPMessage at 0x7fbc7aa365f8>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileURL = \"https://raw.githubusercontent.com/AllenDowney/ThinkPython2/master/code/words.txt\"\n",
    "request.urlretrieve (fileURL, \"words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import `time` so that we can make a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are two different ways to write the desired function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_list1():\n",
    "    \"\"\"Reads lines from a file and builds a list using append.\"\"\"\n",
    "    t = []\n",
    "    fin = open('words.txt')\n",
    "    for line in fin:\n",
    "        word = line.strip()\n",
    "        t.append(word)\n",
    "    return t\n",
    "\n",
    "\n",
    "def make_word_list2():\n",
    "    \"\"\"Reads lines from a file and builds a list using list +.\"\"\"\n",
    "    t = []\n",
    "    fin = open('words.txt')\n",
    "    for line in fin:\n",
    "        word = line.strip()\n",
    "        t = t + [word]\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below, we compare these two functions. Which one is the faster of the two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "t = make_word_list1()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(len(t))\n",
    "print(t[:10])\n",
    "print(elapsed_time, 'seconds')\n",
    "\n",
    "start_time = time.time()\n",
    "t = make_word_list2()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(len(t))\n",
    "print(t[:10])\n",
    "print(elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we want to clean up the book and compute frequency statistics - what are the words in the book, and how many times is each one used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string # Used to get punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, skip_header):\n",
    "    \"\"\"Makes a histogram that contains the words from a file.\n",
    "\n",
    "    filename: string\n",
    "    skip_header: boolean, whether to skip the Gutenberg header\n",
    "   \n",
    "    returns: map from each word to the number of times it appears.\n",
    "    \"\"\"\n",
    "    hist = {} # This is an empty dictionary\n",
    "    fp = open(filename)\n",
    "\n",
    "    if skip_header:\n",
    "        skip_gutenberg_header(fp)\n",
    "\n",
    "    for line in fp:\n",
    "        process_line(line, hist)\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "def skip_gutenberg_header(fp):\n",
    "    \"\"\"Reads from fp until it finds the line that ends the header.\n",
    "    \n",
    "    RMK: You just have to look at the Gutenberg format. That is\n",
    "    how you would know how to write such a function. This had to\n",
    "    be changed.\n",
    "\n",
    "    fp: open file object\n",
    "    \"\"\"\n",
    "    for line in fp:\n",
    "        if line.startswith('*** START OF THIS PROJECT GUTENBERG EBOOK EMMA ***'):\n",
    "            break\n",
    "\n",
    "\n",
    "def process_line(line, hist):\n",
    "    \"\"\"Adds the words in the line to the histogram.\n",
    "\n",
    "    Modifies hist.\n",
    "    \n",
    "    RMK: This is not *pure* function. It modifies\n",
    "    one of its arguments. This is frowned upon\n",
    "    in many circles, but it is one way to do things.\n",
    "\n",
    "    line: string\n",
    "    hist: histogram (map from word to frequency)\n",
    "    \"\"\"\n",
    "    # replace hyphens with spaces before splitting\n",
    "    line = line.replace('-', ' ')\n",
    "    strippables = string.punctuation + string.whitespace\n",
    "\n",
    "    for word in line.split():\n",
    "        # remove punctuation and convert to lowercase\n",
    "        word = word.strip(strippables)\n",
    "        word = word.lower()\n",
    "\n",
    "        # update the histogram\n",
    "        hist[word] = hist.get(word, 0) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to compute word statistics for a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `hist` dictionary object contains all the information about our word stats. It is easy to write functions that compute word count and *unique* word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(hist):\n",
    "    \"\"\"Returns the total of the frequencies in a histogram.\"\"\"\n",
    "    return sum(hist.values())\n",
    "\n",
    "\n",
    "def different_words(hist):\n",
    "    \"\"\"Returns the number of different words in a histogram.\"\"\"\n",
    "    return len(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, our functions for the most commonly occurring words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(hist):\n",
    "    \"\"\"Makes a list of word-freq pairs in descending order of frequency.\n",
    "\n",
    "    hist: map from word to frequency\n",
    "\n",
    "    returns: list of (frequency, word) pairs\n",
    "    \"\"\"\n",
    "    t = []\n",
    "    for key, value in hist.items():\n",
    "        t.append((value, key))\n",
    "\n",
    "    t.sort()\n",
    "    t.reverse()\n",
    "    return t\n",
    "\n",
    "\n",
    "def print_most_common(hist, num=10):\n",
    "    \"\"\"Prints the most commons words in a histgram and their frequencies.\n",
    "    \n",
    "    hist: histogram (map from word to frequency)\n",
    "    num: number of words to print\n",
    "    \"\"\"\n",
    "    t = most_common(hist)\n",
    "    print('The most common words are:')\n",
    "    for freq, word in t[:num]:\n",
    "        print(word, '\\t', freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, now it is time to use all of our functions. Let's try it on *Emma* first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = process_file('Emma.txt', skip_header=True)\n",
    "print('Total number of words:', total_words(hist))\n",
    "print('Number of different words:', different_words(hist))\n",
    "\n",
    "t = most_common(hist)\n",
    "print('The most common words are:')\n",
    "for freq, word in t[0:20]:\n",
    "    print(word, '\\t', freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More File IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `json` module gives us one way to work with dictionary objects, storing and loading them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ourRoom = {'desks':12, 'screens':2, 'people': 20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ourRoom.json','w') as f:\n",
    "    json.dump(ourRoom,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ourRoom.json','r') as f:\n",
    "    newRoom = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'desks': 12, 'screens': 2, 'people': 20}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newRoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newRoom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An easy way to get CSV files in and out of an IPython session is to use `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('2010_Census_Populations_by_Zip_Code.csv')\n",
    "census.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['computedAHZ'] = census['Total Population'] / census['Total Households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['computedAHZ'] - census['Average Household Size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can then write the file back to the csv..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "census.to_csv('2010_Census_Populations_by_Zip_Code.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And then read it back in, in order to check that our changes are reflected in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCensus = pd.read_csv('2010_Census_Populations_by_Zip_Code.csv')\n",
    "newCensus.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indeed. Speaking of `pandas` and `json`, DataFrame can also be read from `json` files, a common format for responses to API calls (such as the one we saw in lab last time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "newCensus.to_json('2010json.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonCensus = pd.read_json('2010json.json')\n",
    "jsonCensus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonCensus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So, even though we think of `json` format as dictionary-like, `pandas` can (sometimes) read it as a DataFrame object. Here is that construction a bit more explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoDict = {'col1':[1,2,3], 'col2':[.4,.45,0], 'col3':[0,0,0]}\n",
    "demoFrame = pd.DataFrame(demoDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demoFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Tuesday, Week 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a tour of IO options for python. The thing you're most likely to use from this in the 'real world' is some interface to a SQL database, but there are others you should be aware of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, in broad strokes, are the main points to be considered:\n",
    "1. Is your data stored in RAM? How much RAM, or *memory* is available on your system?\n",
    "2. Is your data stored on disk? How fast can data be transferred to/from disk?\n",
    "3. What is the file format, and how does it influence IO rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is a depiction of it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"ioflow.png\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see our options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic IO with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe first that you can move yourself around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I just moved 'up' a directory ( as I showed you in the terminal last week ). Let's look around..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, what's in `data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load the *Old Faithful* data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "olf = pd.read_csv('data/legit_olf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's go back home..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('notebooks/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And look around..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was cheating a bit because we used `pandas`. Let's use the native Python capabilities for IO now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import gauss\n",
    "a = [gauss(1.5,2) for i in range(1000000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will write the list `a` to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.6 ms, sys: 4.16 ms, total: 37.7 ms\n",
      "Wall time: 36.6 ms\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('list.pkl','wb') as pklFile: # You need the 'b' in that second argument\n",
    "    %time pickle.dump(a,pklFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In our text, you will find a different approach where the name `pklFile` is bound to the file object, then explicitly closed at the end of the operation. Here, you can see that one effect of the `with...as` construct is that the file is closed when you've finished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pklFile.closed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note another command appearing in the text: `ll`. It is another way to list the contents of the directory, and its default output has a bit more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 9048\r\n",
      "-rw-rw-r-- 1 martin    4593 Sep 10 20:23 Ch02_Infrastructure_Tools.ipynb\r\n",
      "-rw-rw-r-- 1 martin   51571 Sep 10 20:22 Ch04_Data_Structures.ipynb\r\n",
      "-rw-rw-r-- 1 martin   61313 Sep 11 06:42 \u001b[0m\u001b[01;35mioflow.png\u001b[0m\r\n",
      "-rw-rw-r-- 1 martin 9002006 Sep 11 11:21 list.pkl\r\n",
      "-rw-rw-r-- 1 martin  119996 Sep 10 20:24 PyFiWeek2.ipynb\r\n",
      "-rw-rw-r-- 1 martin    8364 Sep 11 11:21 PyIO.ipynb\r\n",
      "-rw-rw-r-- 1 martin    1273 Sep 10 20:28 PyObj.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read our file back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list.pkl','rb') as pklFile: # You need the 'b' in that second argument\n",
    "    b = pickle.load(pklFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's confirm that these two are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That worked. But generally you can use this handy `numpy` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(a,b) # Tolerates inequality below some threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, multiple objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 ms, sys: 11.9 ms, total: 46.5 ms\n",
      "Wall time: 46.4 ms\n",
      "CPU times: user 39.1 ms, sys: 4.37 ms, total: 43.4 ms\n",
      "Wall time: 33.5 ms\n"
     ]
    }
   ],
   "source": [
    "with open('list.pkl','wb') as pklFile:\n",
    "    %time pickle.dump(np.array(a), pklFile)\n",
    "    %time pickle.dump(np.array(a) ** 2, pklFile)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 15884\r\n",
      "-rw-rw-r-- 1 martin     4593 Sep 10 20:23 Ch02_Infrastructure_Tools.ipynb\r\n",
      "-rw-rw-r-- 1 martin    51571 Sep 10 20:22 Ch04_Data_Structures.ipynb\r\n",
      "-rw-rw-r-- 1 martin    61313 Sep 11 06:42 \u001b[0m\u001b[01;35mioflow.png\u001b[0m\r\n",
      "-rw-rw-r-- 1 martin 16000322 Sep 11 11:26 list.pkl\r\n",
      "-rw-rw-r-- 1 martin   119996 Sep 10 20:24 PyFiWeek2.ipynb\r\n",
      "-rw-rw-r-- 1 martin    10227 Sep 11 11:25 PyIO.ipynb\r\n",
      "-rw-rw-r-- 1 martin     1273 Sep 10 20:28 PyObj.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note the the file is double the size it was before. In your text it is remarked that this operation was faster with the use of `np.array`, but that no longer seems to be true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The objects have been *written to disk*, whereas the `a` and `b` should be thought of as object sitting in RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's load those two values back in..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('list.pkl','rb') as pklFile:\n",
    "    x = pickle.load(pklFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What gives? Let's try something else..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('list.pkl','rb') as pklFile:\n",
    "    x = pickle.load(pklFile)\n",
    "    y = pickle.load(pklFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's compare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a[:5]), np.array(a[:5])**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking good, but that was inconvenient. So let's store `x,y` in a dictionary object, and then write that object to our file using `pickle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list.pkl', 'wb') as pklFile:\n",
    "    pickle.dump({'x':x,'y':y}, pklFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, when we load it in and find that it is an dictionary object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('list.pkl','rb') as pklFile:\n",
    "    data = pickle.load(pklFile)\n",
    "for key in data.keys():\n",
    "    print( key, data[key][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Files, or CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we'll do it 'manually', starting with some `pandas` date range data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 5000\n",
    "a = np.random.standard_normal((rows,5))\n",
    "t = pd.date_range(start='2014/1/1', periods=rows, freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we are writing it to a `csv` file manually (in the way that we have done so far):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ape,5.000000'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{0:s},{1:f}\".format('ape',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at that `b` in the second string argument to our writing method. That puts the file object in binary mode. This used to be an issue just for Windows users, but as of *Python3*, everyone has to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.csv','wb') as csvFile:\n",
    "    header = b'data,no1,no2,no3,no4,no5\\n'\n",
    "    csvFile.write(header)\n",
    "    for t_, (no1,no2,no3,no4,no5) in zip(t,a):\n",
    "        s = bytes(\"{0:s},{1:f}{2:f}{3:f}{4:f}{5:f}\".format(t_,no1,no2,no3,no4,no5), 'utf-8')\n",
    "        csvFile.write(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Question for You All*: why couldn't I just prepend that string inside the loop with a `b` as well? What happens if you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before moving on from this painful way of doing IO, let's read that guy back in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.csv','r') as csvFile:\n",
    "    for i in range(5):\n",
    "        print(csvFile.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This really makes you appreciate pandas. More on that in a few..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'CREATE TABLE numbs (Date date,No1 real,No2 real)'\n",
    "con = sq3.connect('numbs.db') # Creating a SQL connection object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note how we have broken this down into:\n",
    "1. A query string - imagine contexts where you might programmatically format such a string.\n",
    "2. A connection object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we're going to execute that query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.commit() # This must be done in order to make the change effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK....so what? So look at the `query` string - it's actually not much of a query, but in fact tells SQL to *create a table*. So that's what it did for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (For fun, try running that same 'query' again)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This will actually put some data into our `numbs` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7facd4aff3b0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "con.execute('INSERT INTO numbs VALUES (?,?,?)',\n",
    "           (dt.datetime.now(), 0.12, 4.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can do the same thing inside of a loop in order to write multiple rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.standard_normal((10000,2)).round(5)\n",
    "\n",
    "for row in data:\n",
    "    con.execute('INSERT INTO numbs VALUES (?,?,?)',\n",
    "                (dt.datetime.now(), row[0],row[1]))\n",
    "con.commit() # NB, this is outside of the loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does anyone else feel like we're flying blind? Let's look at what we've got..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.execute('SELECT * from numbs').fetchmany(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bretty gool! Takeaway:\n",
    "    - Python is already set up to interact with existing (legacy) data frameworks\n",
    "    - You are freed up to deal with just the Python objects - and the occasional piece of SQL syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas supports many file formats. Let's look at a few and compare performance (in terms of IO speed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We begin by generating a dummy dataset for use in our comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.standard_normal((1000000, 5)).round(5)\n",
    "filename = 'numbs' # We'll re-use this, so it's handy to name it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We just saw SQL above. Let's use it to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'CREATE TABLE numbers (No1 real, No2 real, No3 real, No4 real, No5 real)'\n",
    "con = sq3.Connection(filename+'.db')\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here, we'll insert our data and time how long it takes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "con.executemany('INSERT INTO numbers VALUES (?,?,?,?,?)', data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How about reading it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "temp = con.execute('SELECT * FROM numbers').fetchall()\n",
    "print(temp[:2])\n",
    "temp = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Much faster than writing. We can alternatively read results directly into a `numpy` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "query = 'SELECT * FROM numbers WHERE No1 > 0 AND No2 < 0'\n",
    "res = np.array(con.execute(query).fetchall()).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you picture that in your head? No need, we can have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "res = res[::100] # Every hundredth datapoint\n",
    "plt.plot(res[:,0],res[:,1],'ro')\n",
    "plt.grid(True)\n",
    "plt.xlim(-.5,4.5)\n",
    "plt.ylim(-4.5,.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the examples above, we were using SQL. Let's use `pandas` to load a SQL table into *RAM* instead, dealing with it as a Python object *in memory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas.io.sql as pds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data = pds.read_sql('SELECT * FROM numbers',con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (*RMK* here and previously a *wildcard* symbol \\* is used.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's do the equivalent query on our *DataFrame* object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['No1'] > 0) & (data['No2'] < 0)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have already seen how to deal with `csv` files. Note also that we can use *Excel* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data[:100000].to_excel(filename + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time data[:100000].to_csv(filename + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (But it takes longer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tab.h5' # New filename for HDF5 format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening the file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = tb.open_file(filename, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 2000000 # The number of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's describe the table we desire: it has a datetime column, two int and two float columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_des = {\n",
    "'Date': tb.StringCol(26, pos=1),\n",
    "'No1': tb.IntCol(pos=2),\n",
    "'No2': tb.IntCol(pos=3),\n",
    "'No3': tb.Float64Col(pos=4),\n",
    "'No4': tb.Float64Col(pos=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = tb.Filters(complevel=0) # no compression\n",
    "\n",
    "tab = h5.create_table('/', 'ints_floats', row_des,\n",
    "    title = 'Integers and Floats',\n",
    "    expectedrows = rows, filters = filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = tab.row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_int = np.random.randint(0,10000,size=(rows,2))\n",
    "ran_flo = np.random.standard_normal((rows,2)).round(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, let's write our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.81 s, sys: 91.6 ms, total: 5.91 s\n",
      "Wall time: 5.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(rows):\n",
    "    pointer['Date'] = dt.datetime.now()\n",
    "    pointer['No1'] = ran_int[i,0]\n",
    "    pointer['No2'] = ran_int[i,1]\n",
    "    pointer['No3'] = ran_flo[i,0]\n",
    "    pointer['No4'] = ran_flo[i,1]\n",
    "    pointer.append() # Advances the pointer.\n",
    "tab.flush() # Like 'commit' in the SQL examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/ints_floats (Table(2000000,)) 'Integers and Floats'\n",
       "  description := {\n",
       "  \"Date\": StringCol(itemsize=26, shape=(), dflt=b'', pos=0),\n",
       "  \"No1\": Int32Col(shape=(), dflt=0, pos=1),\n",
       "  \"No2\": Int32Col(shape=(), dflt=0, pos=2),\n",
       "  \"No3\": Float64Col(shape=(), dflt=0.0, pos=3),\n",
       "  \"No4\": Float64Col(shape=(), dflt=0.0, pos=4)}\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (2621,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
