{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPS600 - Python Programming for Finance \n",
    "###  \n",
    "<img src=\"https://www.syracuse.edu/wp-content/themes/g6-carbon/img/syracuse-university-seal.svg?ver=6.3.9\" style=\"width: 200px;\"/>\n",
    "\n",
    "# More Practice & Scripts\n",
    "\n",
    "###  September 27, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is one quick way to download a text from inside our Python session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Emma.txt', <http.client.HTTPMessage at 0x7f8b4bf7ccc0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    "request.urlretrieve (\"https://www.gutenberg.org/files/158/158-0.txt\", \"Emma.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While we're at it, let's download the `words.txt` from *Think Python*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('words.txt', <http.client.HTTPMessage at 0x7f8b4b723518>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileURL = \"https://raw.githubusercontent.com/AllenDowney/ThinkPython2/master/code/words.txt\"\n",
    "request.urlretrieve (fileURL, \"words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's import `time` so that we can make a comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are two different ways to write the desired function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_list1():\n",
    "    \"\"\"Reads lines from a file and builds a list using append.\"\"\"\n",
    "    t = []\n",
    "    fin = open('words.txt')\n",
    "    for line in fin:\n",
    "        word = line.strip()\n",
    "        t.append(word)\n",
    "    return t\n",
    "# The next one is very slow; we don't need it.\n",
    "\n",
    "def make_word_list2():\n",
    "    \"\"\"Reads lines from a file and builds a list using list +.\"\"\"\n",
    "    t = []\n",
    "    fin = open('words.txt')\n",
    "    for line in fin:\n",
    "        word = line.strip()\n",
    "        t = t + [word]\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below, we compare these two functions. Which one is the faster of the two?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "t = make_word_list1()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(len(t))\n",
    "print(t[:10])\n",
    "print(elapsed_time, 'seconds')\n",
    "\n",
    "start_time = time.time()\n",
    "t = make_word_list2()\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(len(t))\n",
    "print(t[:10])\n",
    "print(elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whoa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we want to clean up the book and compute frequency statistics - what are the words in the book, and how many times is each one used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string # Used to get punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename, skip_header):\n",
    "    \"\"\"Makes a histogram that contains the words from a file.\n",
    "\n",
    "    filename: string\n",
    "    skip_header: boolean, whether to skip the Gutenberg header\n",
    "   \n",
    "    returns: map from each word to the number of times it appears.\n",
    "    \"\"\"\n",
    "    hist = {} # This is an empty dictionary\n",
    "    fp = open(filename)\n",
    "\n",
    "    if skip_header:\n",
    "        skip_gutenberg_header(fp)\n",
    "\n",
    "    for line in fp:\n",
    "        process_line(line, hist)\n",
    "\n",
    "    return hist\n",
    "\n",
    "\n",
    "def skip_gutenberg_header(fp):\n",
    "    \"\"\"Reads from fp until it finds the line that ends the header.\n",
    "    \n",
    "    RMK: You just have to look at the Gutenberg format. That is\n",
    "    how you would know how to write such a function. This had to\n",
    "    be changed.\n",
    "\n",
    "    fp: open file object\n",
    "    \"\"\"\n",
    "    for line in fp:\n",
    "        if line.startswith('*** START OF TH'):\n",
    "            break\n",
    "\n",
    "\n",
    "def process_line(line, hist):\n",
    "    \"\"\"Adds the words in the line to the histogram.\n",
    "\n",
    "    Modifies hist.\n",
    "    \n",
    "    RMK: This is not *pure* function. It modifies\n",
    "    one of its arguments. This is frowned upon\n",
    "    in many circles, but it is one way to do things.\n",
    "\n",
    "    line: string\n",
    "    hist: histogram (map from word to frequency)\n",
    "    \"\"\"\n",
    "    # replace hyphens with spaces before splitting\n",
    "    line = line.replace('-', ' ')\n",
    "    strippables = string.punctuation + string.whitespace\n",
    "\n",
    "    for word in line.split():\n",
    "        # remove punctuation and convert to lowercase\n",
    "        word = word.strip(strippables)\n",
    "        word = word.lower()\n",
    "\n",
    "        # update the histogram\n",
    "        hist[word] = hist.get(word, 0) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want to compute word statistics for a document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `hist` dictionary object contains all the information about our word stats. It is easy to write functions that compute word count and *unique* word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_words(hist):\n",
    "    \"\"\"Returns the total of the frequencies in a histogram.\"\"\"\n",
    "    return sum(hist.values())\n",
    "\n",
    "\n",
    "def different_words(hist):\n",
    "    \"\"\"Returns the number of different words in a histogram.\"\"\"\n",
    "    return len(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, our functions for the most commonly occurring words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(hist):\n",
    "    \"\"\"Makes a list of word-freq pairs in descending order of frequency.\n",
    "\n",
    "    hist: map from word to frequency\n",
    "\n",
    "    returns: list of (frequency, word) pairs\n",
    "    \"\"\"\n",
    "    t = []\n",
    "    for key, value in hist.items():\n",
    "        t.append((value, key))\n",
    "\n",
    "    t.sort()\n",
    "    t.reverse()\n",
    "    return t\n",
    "\n",
    "\n",
    "def print_most_common(hist, num=10):\n",
    "    \"\"\"Prints the most commons words in a histgram and their frequencies.\n",
    "    \n",
    "    hist: histogram (map from word to frequency)\n",
    "    num: number of words to print\n",
    "    \"\"\"\n",
    "    t = most_common(hist)\n",
    "    print('The most common words are:')\n",
    "    for freq, word in t[:num]:\n",
    "        print(word, '\\t', freq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, now it is time to use all of our functions. Let's try it on *Emma* first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words: 164029\n",
      "Number of different words: 8893\n",
      "The most common words are:\n",
      "the \t 5353\n",
      "to \t 5303\n",
      "and \t 4889\n",
      "of \t 4392\n",
      "a \t 3170\n",
      "i \t 2861\n",
      "her \t 2445\n",
      "it \t 2407\n",
      "was \t 2394\n",
      "she \t 2334\n",
      "in \t 2233\n",
      "not \t 2146\n",
      "be \t 1984\n",
      "you \t 1900\n",
      "he \t 1770\n",
      "that \t 1766\n",
      "had \t 1622\n",
      "as \t 1435\n",
      "but \t 1364\n",
      "for \t 1353\n"
     ]
    }
   ],
   "source": [
    "hist = process_file('Emma.txt', skip_header=True)\n",
    "print('Total number of words:', total_words(hist))\n",
    "print('Number of different words:', different_words(hist))\n",
    "\n",
    "t = most_common(hist)\n",
    "print('The most common words are:')\n",
    "for freq, word in t[0:20]:\n",
    "    print(word, '\\t', freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
